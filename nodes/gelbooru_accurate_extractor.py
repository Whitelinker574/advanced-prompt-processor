"""
Gelbooruå‡†ç¡®æ ‡ç­¾æå–å™¨ - ä½¿ç”¨Gelbooru Tag APIè·å–å‡†ç¡®çš„æ ‡ç­¾åˆ†ç±»
"""
import os
import re
import json
import requests
import random
import numpy as np
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter
import time

# è·¨å¹³å°winregå¯¼å…¥
try:
    import winreg
    HAS_WINREG = True
except ImportError:
    HAS_WINREG = False


def get_system_proxy():
    """è·å–ç³»ç»Ÿä»£ç†è®¾ç½®"""
    try:
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        http_proxy = os.environ.get('HTTP_PROXY') or os.environ.get('http_proxy')
        https_proxy = os.environ.get('HTTPS_PROXY') or os.environ.get('https_proxy')
        
        if http_proxy or https_proxy:
            return {'http': http_proxy, 'https': https_proxy}
        
        # Windowsæ³¨å†Œè¡¨æ£€æµ‹ (ä»…Windows)
        if HAS_WINREG:
            try:
                reg_key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, 
                                        r"Software\Microsoft\Windows\CurrentVersion\Internet Settings")
                proxy_enable = winreg.QueryValueEx(reg_key, "ProxyEnable")[0]
                if proxy_enable:
                    proxy_server = winreg.QueryValueEx(reg_key, "ProxyServer")[0]
                    winreg.CloseKey(reg_key)
                    proxy_url = f"http://{proxy_server}"
                    return {'http': proxy_url, 'https': proxy_url}
                else:
                    winreg.CloseKey(reg_key)
            except:
                pass
    except:
        pass
    
    return None


def make_robust_request(url, timeout=30, max_retries=3):
    """åˆ›å»ºå…·æœ‰ä»£ç†æ”¯æŒå’Œé‡è¯•æœºåˆ¶çš„ç½‘ç»œè¯·æ±‚"""
    session = requests.Session()
    
    # è·å–å¹¶åº”ç”¨ç³»ç»Ÿä»£ç†
    system_proxies = get_system_proxy()
    if system_proxies:
        session.proxies.update(system_proxies)
        print(f"ğŸŒ Gelbooruä½¿ç”¨ä»£ç†: {system_proxies}")
    
    # é…ç½®é‡è¯•ç­–ç•¥
    try:
        # æ–°ç‰ˆæœ¬urllib3ä½¿ç”¨allowed_methods
        retry_strategy = Retry(
            total=max_retries,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["HEAD", "GET", "OPTIONS"],
            backoff_factor=1
        )
    except TypeError:
        # æ—§ç‰ˆæœ¬urllib3ä½¿ç”¨method_whitelist
        retry_strategy = Retry(
            total=max_retries,
            status_forcelist=[429, 500, 502, 503, 504],
            method_whitelist=["HEAD", "GET", "OPTIONS"],
            backoff_factor=1
        )
    
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    
    # å°è¯•å¤šç§è¿æ¥æ–¹å¼
    attempts = [
        {'verify': False, 'timeout': timeout},          # å…ˆå°è¯•æ— SSLéªŒè¯ï¼ˆé€šå¸¸æ›´ç¨³å®šï¼‰
        {'verify': True, 'timeout': timeout},           # å†å°è¯•SSLéªŒè¯
        {'verify': False, 'timeout': timeout * 2},      # å¢åŠ è¶…æ—¶æ—¶é—´å†è¯•
    ]
    
    last_error = None
    
    for i, attempt in enumerate(attempts, 1):
        try:
            print(f"ğŸŒ Gelbooruå°è¯• {i}/{len(attempts)}: è¿æ¥ {url[:50]}...")
            response = session.get(url, **attempt)
            
            if response.status_code == 200:
                print(f"âœ… Gelbooruè¿æ¥æˆåŠŸ (å°è¯• {i})")
                return response
            else:
                print(f"âš ï¸  HTTP {response.status_code}, ç»§ç»­å°è¯•...")
                
        except requests.exceptions.ProxyError as e:
            print(f"ğŸ”§ ä»£ç†é”™è¯¯ (å°è¯• {i}): {e}")
            # ä»£ç†é”™è¯¯æ—¶ï¼Œæ¸…é™¤ä»£ç†è®¾ç½®å°è¯•ç›´è¿
            session.proxies.clear()
            last_error = e
            continue
            
        except requests.exceptions.ConnectTimeout as e:
            print(f"â° è¿æ¥è¶…æ—¶ (å°è¯• {i}): {e}")
            last_error = e
            continue
            
        except Exception as e:
            print(f"âŒ è¿æ¥å¤±è´¥ (å°è¯• {i}): {e}")
            last_error = e
            continue
    
    # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
    print(f"âŒ Gelbooruæ‰€æœ‰è¿æ¥å°è¯•éƒ½å¤±è´¥: {last_error}")
    raise requests.exceptions.ConnectTimeout(f"æ— æ³•è¿æ¥åˆ° {url}")


class GelbooruAccurateExtractor:
    """ä½¿ç”¨Gelbooru Tag APIè·å–å‡†ç¡®æ ‡ç­¾åˆ†ç±»çš„æå–å™¨"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "enable_gelbooru": ("BOOLEAN", {"default": True, "tooltip": "æ˜¯å¦å¯ç”¨Gelbooruæ ‡ç­¾è·å–"}),
                "site": (["Gelbooru", "Rule34"], {"default": "Gelbooru"}),
                "OR_tags": ("STRING", {"default": "", "multiline": True}),
                "AND_tags": ("STRING", {"default": "", "multiline": True}),
                "exclude_tag": ("STRING", {"default": "animated,", "multiline": True}),
                "Safe": ("BOOLEAN", {"default": True}),
                "Questionable": ("BOOLEAN", {"default": True}),
                "Explicit": ("BOOLEAN", {"default": False}),
                "score": ("INT", {"default": 10, "min": 0, "max": 1000}),
                "count": ("INT", {"default": 1, "min": 1, "max": 10}),
                "random_seed": ("INT", {"default": 0, "min": 0, "max": 0xffffffffffffffff}),
                "auto_random_seed": ("BOOLEAN", {"default": True, "tooltip": "è‡ªåŠ¨ç”Ÿæˆ9ä½æ•°éšæœºç§å­"}),
                
                # æ ‡ç­¾åˆ†ç±»é€‰æ‹©ï¼ˆæŒ‰æ­£ç¡®é¡ºåºï¼‰
                "include_artists": ("BOOLEAN", {"default": True}),
                "include_characters": ("BOOLEAN", {"default": True}),
                "include_copyrights": ("BOOLEAN", {"default": True}),
                "include_general": ("BOOLEAN", {"default": True}),
                "include_metadata": ("BOOLEAN", {"default": False}),
                
                # è¾“å‡ºæ ¼å¼é€‰æ‹©ï¼ˆæŒ‰æ­£ç¡®é¡ºåºï¼‰
                "artist_format": (["original", "by_prefix", "parentheses", "brackets", "underscores"], {"default": "by_prefix"}),
                "character_format": (["original", "parentheses", "brackets", "underscores"], {"default": "original"}),
                "copyright_format": (["original", "parentheses", "brackets", "from_prefix"], {"default": "original"}),
                "general_format": (["original", "parentheses", "brackets", "underscores"], {"default": "original"}),
                "metadata_format": (["original", "hidden", "parentheses"], {"default": "hidden"}),
                
                # æ•°é‡é™åˆ¶ï¼ˆæŒ‰æ­£ç¡®é¡ºåºï¼‰
                "max_artists": ("INT", {"default": 5, "min": 0, "max": 20}),
                "max_characters": ("INT", {"default": 5, "min": 0, "max": 20}),
                "max_copyrights": ("INT", {"default": 3, "min": 0, "max": 10}),
                "max_general": ("INT", {"default": 30, "min": 0, "max": 100}),
                "max_metadata": ("INT", {"default": 10, "min": 0, "max": 50}),
                
                # ç»„åˆé€‰é¡¹
                "separator": (["comma", "space", "newline"], {"default": "comma"}),
                "use_tag_api": ("BOOLEAN", {"default": True}),
            },
            "optional": {
                "user_id": ("STRING", {"default": ""}),
                "api_key": ("STRING", {"default": ""}),
            }
        }
    
    # æŒ‰æ­£ç¡®é¡ºåºè¿”å›ï¼šArtist-Character-Copyright-General-Metadata
    RETURN_TYPES = ("STRING", "STRING", "STRING", "STRING", "STRING", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("combined_tags", "artists", "characters", "copyrights", "general_tags", "metadata", "image_urls", "tag_info")
    FUNCTION = "extract_accurate_tags"
    CATEGORY = "Advanced Prompt Processor/Gelbooru"
    
    @classmethod
    def IS_CHANGED(cls, **kwargs):
        """å¼ºåˆ¶èŠ‚ç‚¹æ¯æ¬¡éƒ½é‡æ–°æ‰§è¡Œï¼Œé¿å…ComfyUIç¼“å­˜"""
        import time
        return time.time()
    
    def __init__(self):
        # Gelbooruæ ‡ç­¾ç±»å‹æ˜ å°„ï¼ˆæ•°å­—å¯¹åº”ç±»å‹ï¼‰
        self.gelbooru_tag_types = {
            0: 'general',     # ä¸€èˆ¬æ ‡ç­¾
            1: 'artists',     # ç”»å¸ˆ
            3: 'copyrights',  # ç‰ˆæƒ
            4: 'characters',  # è§’è‰²
            5: 'metadata'     # å…ƒæ•°æ®
        }
        
        # å¤‡ç”¨åˆ†ç±»æ¨¡å¼çš„æŒ‡ç¤ºå™¨ï¼ˆå½“APIä¸å¯ç”¨æ—¶ï¼‰
        self.fallback_artist_patterns = [
            'artist:', 'by_', 'drawn_by_', '_artist', 'pixiv_id', 'twitter_username',
            'artstation_username', 'deviantart_username', 'tumblr_username',
            'artist_name', 'art_by'
        ]
        
        self.fallback_character_patterns = [
            'character:', '_character', r'_\(.*\)$', 'girl$', 'boy$', 'chan$', 'kun$'
        ]
        
        self.fallback_copyright_patterns = [
            'copyright:', 'series:', 'from_', '_series$', '_game$', '_anime$',
            'touhou', 'fate/', 'pokemon', 'original'
        ]
        
        self.fallback_metadata_patterns = [
            'rating:', 'score:', 'favcount:', 'id:', 'width:', 'height:', 'filesize:',
            'date:', 'source:', 'pool:', 'parent:', 'has_', 'tagme', 'translation_request',
            'commentary', 'md5:', 'status:', 'approver:', 'uploader:', 'highres',
            'absurdres', 'incredibly_absurdres', 'huge_filesize', 'lowres', 'jpeg_artifacts'
        ]
    
    def extract_accurate_tags(self, enable_gelbooru, site, OR_tags, AND_tags, exclude_tag, Safe, Questionable, Explicit, 
                             score, count, random_seed, auto_random_seed,
                             include_artists, include_characters, include_copyrights, include_general, include_metadata,
                             artist_format, character_format, copyright_format, general_format, metadata_format,
                             max_artists, max_characters, max_copyrights, max_general, max_metadata,
                             separator, use_tag_api,
                             user_id="", api_key=""):
        """ä½¿ç”¨Gelbooru Tag APIè·å–å‡†ç¡®çš„æ ‡ç­¾åˆ†ç±»"""
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨Gelbooru
        if not enable_gelbooru:
            return self._empty_result("Gelbooruæ ‡ç­¾è·å–å·²ç¦ç”¨")
        
        if auto_random_seed:
            # ç”Ÿæˆ9ä½æ•°éšæœºç§å­ (100000000 - 999999999)
            new_seed = random.randint(100000000, 999999999)
            random.seed(new_seed)
            np.random.seed(new_seed)
            print(f"ğŸ² è‡ªåŠ¨ç”Ÿæˆ9ä½æ•°éšæœºç§å­: {new_seed}")
        elif random_seed != 0:
            random.seed(random_seed)
            np.random.seed(random_seed)
            print(f"ä½¿ç”¨æŒ‡å®šéšæœºç§å­: {random_seed}")
        else:
            print("ä½¿ç”¨ç³»ç»Ÿé»˜è®¤éšæœºç§å­")
        
        try:
            # 1. è·å–å›¾ç‰‡æ•°æ®
            posts_data = self._get_posts_data(
                site, OR_tags, AND_tags, exclude_tag, Safe, Questionable, Explicit,
                score, count, user_id, api_key
            )
            
            if not posts_data:
                return self._empty_result("æœªæ‰¾åˆ°åŒ¹é…çš„å›¾ç‰‡")
            
            # 2. æå–æ‰€æœ‰æ ‡ç­¾
            all_tags = self._extract_tags_from_posts(posts_data)
            
            if not all_tags:
                return self._empty_result("å›¾ç‰‡ä¸­æ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾")
            
            # 3. ä½¿ç”¨Tag APIè·å–å‡†ç¡®åˆ†ç±»
            categorized_tags = self._categorize_tags_with_api(
                all_tags, site, user_id, api_key, use_tag_api
            )
            
            # 4. æŒ‰æ­£ç¡®é¡ºåºæ ¼å¼åŒ–æ ‡ç­¾ï¼šArtist-Character-Copyright-General-Metadata
            formatted_artists = self._format_tags(categorized_tags['artists'][:max_artists], artist_format, "artist")
            formatted_characters = self._format_tags(categorized_tags['characters'][:max_characters], character_format, "character")
            formatted_copyrights = self._format_tags(categorized_tags['copyrights'][:max_copyrights], copyright_format, "copyright")
            formatted_general = self._format_tags(categorized_tags['general'][:max_general], general_format, "general")
            formatted_metadata = self._format_tags(categorized_tags['metadata'][:max_metadata], metadata_format, "metadata")
            
            # 5. æŒ‰æ­£ç¡®é¡ºåºç»„åˆè¾“å‡º
            combined_tags = self._combine_tags_in_order(
                [
                    (formatted_artists, include_artists),
                    (formatted_characters, include_characters),
                    (formatted_copyrights, include_copyrights),
                    (formatted_general, include_general),
                    (formatted_metadata, include_metadata)
                ],
                separator
            )
            
            # 6. æ”¶é›†å›¾ç‰‡URLs
            image_urls = [post.get("file_url", "") for post in posts_data]
            
            # 7. ç”Ÿæˆä¿¡æ¯
            tag_counts = {
                'artists': len(categorized_tags['artists']),
                'characters': len(categorized_tags['characters']),
                'copyrights': len(categorized_tags['copyrights']),
                'general': len(categorized_tags['general']),
                'metadata': len(categorized_tags['metadata'])
            }
            
            tag_info = f"ä»{site}è·å–{len(posts_data)}å¼ å›¾ç‰‡ | " + " | ".join([f"{k}:{v}" for k, v in tag_counts.items()])
            
            return (
                combined_tags,
                formatted_artists,
                formatted_characters,
                formatted_copyrights,
                formatted_general,
                formatted_metadata,
                "\n".join(image_urls),
                tag_info
            )
            
        except Exception as e:
            error_msg = f"å‡†ç¡®æ ‡ç­¾æå–å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return self._empty_result(error_msg)
    
    def _get_posts_data(self, site, OR_tags, AND_tags, exclude_tag, Safe, Questionable, Explicit,
                       score, count, user_id, api_key):
        """è·å–å›¾ç‰‡æ•°æ®"""
        # å¤„ç†æŸ¥è¯¢å‚æ•°
        AND_tags_processed = self._process_tags(AND_tags)
        OR_tags_processed = self._process_or_tags(OR_tags, site)
        exclude_tag_processed = self._process_exclude_tags(exclude_tag)
        rate_exclusion = self._build_rating_exclusion(Safe, Questionable, Explicit, site)
        
        # æ„å»ºAPI URL
        base_url = "https://api.rule34.xxx/index.php" if site == "Rule34" else "https://gelbooru.com/index.php"
        
        query_params = (
            f"page=dapi&s=post&q=index&tags=sort%3arandom+"
            f"{exclude_tag_processed}+{OR_tags_processed}+{AND_tags_processed}+{rate_exclusion}"
            f"+score%3a>{score}&api_key={api_key}&user_id={user_id}&limit={count}&json=1"
        )
        url = f"{base_url}?{query_params}".replace("-+", "")
        url = re.sub(r"\++", "+", url)
        
        print(f"ğŸ” ä»{site}è·å–å›¾ç‰‡æ•°æ®...")
        
        # å‘èµ·è¯·æ±‚
        response = make_robust_request(url, timeout=30)
        
        if site == "Rule34":
            posts = response.json()
        else:
            posts = response.json().get('post', [])
        
        return posts
    
    def _extract_tags_from_posts(self, posts):
        """ä»å›¾ç‰‡æ•°æ®ä¸­æå–æ‰€æœ‰æ ‡ç­¾"""
        all_tags = []
        for post in posts:
            tags = post.get("tags", "").strip()
            if tags:
                post_tags = [tag.strip() for tag in tags.split() if tag.strip()]
                all_tags.extend(post_tags)
        
        # å»é‡å¹¶ä¿æŒé¡ºåº
        unique_tags = list(dict.fromkeys(all_tags))
        return unique_tags
    
    def _categorize_tags_with_api(self, tags, site, user_id, api_key, use_tag_api):
        """ä½¿ç”¨Gelbooru Tag APIè·å–å‡†ç¡®çš„æ ‡ç­¾åˆ†ç±»"""
        categorized = {
            'artists': [],
            'characters': [],
            'copyrights': [],
            'general': [],
            'metadata': []
        }
        
        if site != "Gelbooru" or not use_tag_api or not user_id or not api_key:
            print("âš ï¸  è·³è¿‡Tag APIï¼Œä½¿ç”¨å¤‡ç”¨åˆ†ç±»æ–¹æ³•")
            return self._fallback_categorize_tags(tags)
        
        print(f"ğŸ” ä½¿ç”¨Tag APIè·å–{len(tags)}ä¸ªæ ‡ç­¾çš„å‡†ç¡®åˆ†ç±»...")
        
        # åˆ†æ‰¹å¤„ç†æ ‡ç­¾ï¼Œé¿å…URLè¿‡é•¿
        batch_size = 20
        for i in range(0, len(tags), batch_size):
            batch_tags = tags[i:i+batch_size]
            try:
                batch_result = self._get_tag_types_batch(batch_tags, user_id, api_key)
                
                for tag, tag_type in batch_result.items():
                    if tag_type in self.gelbooru_tag_types:
                        category = self.gelbooru_tag_types[tag_type]
                        categorized[category].append(tag)
                        print(f"âœ… {tag} -> {category} (type {tag_type})")
                    else:
                        # æœªçŸ¥ç±»å‹ï¼Œå½’ä¸ºgeneral
                        categorized['general'].append(tag)
                        print(f"âš ï¸  {tag} -> general (unknown type {tag_type})")
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                time.sleep(0.1)
                
            except Exception as e:
                print(f"âš ï¸  æ‰¹æ¬¡{i//batch_size + 1}å¤„ç†å¤±è´¥: {e}")
                # å¯¹å¤±è´¥çš„æ‰¹æ¬¡ä½¿ç”¨å¤‡ç”¨åˆ†ç±»
                print(f"âš ï¸  å¯¹æ‰¹æ¬¡{i//batch_size + 1}ä½¿ç”¨å¤‡ç”¨åˆ†ç±»: {batch_tags}")
                fallback_result = self._fallback_categorize_tags(batch_tags)
                for category, tag_list in fallback_result.items():
                    if tag_list:
                        print(f"ğŸ“‹ å¤‡ç”¨åˆ†ç±» {category}: {tag_list}")
                        categorized[category].extend(tag_list)
        
        return categorized
    
    def _get_tag_types_batch(self, tags, user_id, api_key):
        """æ‰¹é‡è·å–æ ‡ç­¾ç±»å‹"""
        # ä½¿ç”¨Gelbooru Tag APIçš„nameså‚æ•°ï¼Œéœ€è¦è¿›è¡ŒURLç¼–ç 
        import urllib.parse
        names_param = " ".join(tags)
        names_encoded = urllib.parse.quote(names_param)
        url = f"https://gelbooru.com/index.php?page=dapi&s=tag&q=index&names={names_encoded}&api_key={api_key}&user_id={user_id}&json=1"
        
        print(f"ğŸ” Tag APIè¯·æ±‚: {url[:100]}...")
        response = make_robust_request(url, timeout=15)
        tag_data = response.json()
        
        print(f"ğŸ“„ Tag APIå“åº”ç±»å‹: {type(tag_data)}")
        if isinstance(tag_data, list):
            print(f"ğŸ“Š æ‰¾åˆ° {len(tag_data)} ä¸ªæ ‡ç­¾ä¿¡æ¯")
        
        # è§£æå“åº”ï¼Œè·å–æ ‡ç­¾ç±»å‹
        tag_types = {}
        
        # Gelbooru APIè¿”å›çš„æ˜¯dictæ ¼å¼ï¼Œæ ‡ç­¾æ•°æ®åœ¨'tag'é”®ä¸‹
        if isinstance(tag_data, dict) and 'tag' in tag_data:
            tag_list = tag_data['tag']
            if isinstance(tag_list, list):
                print(f"ğŸ“Š è§£æåˆ° {len(tag_list)} ä¸ªæ ‡ç­¾")
                for tag_info in tag_list:
                    tag_name = tag_info.get('name', '')
                    tag_type = tag_info.get('type', 0)  # typeå­—æ®µåŒ…å«æ ‡ç­¾ç±»å‹
                    if tag_name:
                        tag_types[tag_name] = tag_type
                        print(f"ğŸ·ï¸  {tag_name}: type={tag_type}")
            else:
                print(f"âš ï¸  'tag'å­—æ®µä¸æ˜¯åˆ—è¡¨: {type(tag_list)}")
        elif isinstance(tag_data, list):
            # å¤‡ç”¨å¤„ç†ï¼šå¦‚æœç›´æ¥æ˜¯åˆ—è¡¨
            print(f"ğŸ“Š ç›´æ¥åˆ—è¡¨æ ¼å¼ï¼Œè§£æ {len(tag_data)} ä¸ªæ ‡ç­¾")
            for tag_info in tag_data:
                tag_name = tag_info.get('name', '')
                tag_type = tag_info.get('type', 0)
                if tag_name:
                    tag_types[tag_name] = tag_type
                    print(f"ğŸ·ï¸  {tag_name}: type={tag_type}")
        else:
            print(f"âš ï¸  æ„å¤–çš„APIå“åº”æ ¼å¼: {type(tag_data)}")
            if isinstance(tag_data, dict):
                print(f"ğŸ“‹ å“åº”é”®: {list(tag_data.keys())}")
        
        print(f"ğŸ“‹ æ‰¹æ¬¡ç»“æœ: {len(tag_types)} ä¸ªæ ‡ç­¾è·å¾—ç±»å‹ä¿¡æ¯")
        return tag_types
    
    def _fallback_categorize_tags(self, tags):
        """å¤‡ç”¨çš„æ ‡ç­¾åˆ†ç±»æ–¹æ³•ï¼ˆåŸºäºæ¨¡å¼åŒ¹é…ï¼‰"""
        categorized = {
            'artists': [],
            'characters': [],
            'copyrights': [],
            'general': [],
            'metadata': []
        }
        
        for tag in tags:
            tag_lower = tag.lower()
            
            # å…ƒæ•°æ®æ ‡ç­¾
            if any(pattern in tag_lower for pattern in self.fallback_metadata_patterns):
                categorized['metadata'].append(tag)
            # ç”»å¸ˆæ ‡ç­¾
            elif any(pattern in tag_lower for pattern in self.fallback_artist_patterns) or self._is_likely_artist(tag):
                categorized['artists'].append(tag)
            # è§’è‰²æ ‡ç­¾
            elif any(re.search(pattern, tag_lower) for pattern in self.fallback_character_patterns) or self._is_likely_character(tag):
                categorized['characters'].append(tag)
            # ç‰ˆæƒæ ‡ç­¾
            elif any(pattern in tag_lower for pattern in self.fallback_copyright_patterns) or self._is_likely_copyright(tag):
                categorized['copyrights'].append(tag)
            # å…¶ä»–å½’ä¸ºä¸€èˆ¬æ ‡ç­¾
            else:
                categorized['general'].append(tag)
        
        return categorized
    
    def _is_likely_artist(self, tag):
        """åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯ç”»å¸ˆæ ‡ç­¾"""
        # æ›´ä¸¥æ ¼çš„ç”»å¸ˆåˆ¤æ–­ï¼Œé¿å…è¯¯åˆ†ç±»
        artist_patterns = [
            r'^[a-z]+_[a-z]+_artist$',  # æ˜ç¡®çš„ç”»å¸ˆæ ‡ç­¾
            r'^\w+_\(artist\)$',        # å¸¦(artist)æ ‡è®°çš„
        ]
        return any(re.search(pattern, tag.lower()) for pattern in artist_patterns)
    
    def _is_likely_character(self, tag):
        """åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯è§’è‰²æ ‡ç­¾"""
        character_patterns = [
            r'.*_\(.*\)$',       # å¸¦æ‹¬å·çš„è§’è‰²å
        ]
        return any(re.search(pattern, tag.lower()) for pattern in character_patterns)
    
    def _is_likely_copyright(self, tag):
        """åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯ç‰ˆæƒæ ‡ç­¾"""
        copyright_patterns = [
            r'.*_series$',       # ç³»åˆ—å
            r'.*_game$',         # æ¸¸æˆå
            r'.*_anime$',        # åŠ¨ç”»å
        ]
        return any(re.search(pattern, tag.lower()) for pattern in copyright_patterns)
    
    def _process_tags(self, tags_str):
        """å¤„ç†ANDæ ‡ç­¾"""
        if not tags_str:
            return ""
        tags = tags_str.rstrip(',').rstrip(' ').split(',')
        tags = [item.strip().replace(' ', '_').replace('\\', '') for item in tags]
        tags = [item for item in tags if item]
        return '+'.join(tags) if len(tags) > 1 else (tags[0] if tags else '')
    
    def _process_or_tags(self, tags_str, site):
        """å¤„ç†ORæ ‡ç­¾"""
        if not tags_str:
            return ""
        tags = tags_str.rstrip(',').rstrip(' ').split(',')
        tags = [item.strip().replace(' ', '_').replace('\\', '') for item in tags]
        tags = [item for item in tags if item]
        if len(tags) > 1:
            if site == "Rule34":
                return '( ' + ' ~ '.join(tags) + ' )'
            else:
                return '{' + ' ~ '.join(tags) + '}'
        return tags[0] if tags else ''
    
    def _process_exclude_tags(self, tags_str):
        """å¤„ç†æ’é™¤æ ‡ç­¾"""
        if not tags_str:
            return ""
        return '+'.join('-' + item.strip().replace(' ', '_') for item in tags_str.split(',') if item.strip())
    
    def _build_rating_exclusion(self, Safe, Questionable, Explicit, site):
        """æ„å»ºè¯„çº§æ’é™¤"""
        rate_exclusion = ""
        if not Safe: 
            if site == "Rule34":
                rate_exclusion += "+-rating%3asafe"
            elif site == "Gelbooru":
                rate_exclusion += "+-rating%3ageneral"
        
        if not Questionable: 
            if site == "Rule34":
                rate_exclusion += "+-rating%3aquestionable" 
            elif site == "Gelbooru":
                rate_exclusion += "+-rating%3aquestionable+-rating%3aSensitive"
        
        if not Explicit: 
            if site == "Rule34":
                rate_exclusion += "+-rating%3aexplicit" 
            elif site == "Gelbooru":
                rate_exclusion += "+-rating%3aexplicit"
        
        return rate_exclusion
    
    def _format_tags(self, tags, format_type, category):
        """æ ¼å¼åŒ–æ ‡ç­¾"""
        if not tags:
            return ""
        
        if format_type == "hidden":
            return ""
        
        formatted_tags = []
        for tag in tags:
            if format_type == "original":
                formatted_tags.append(tag)
            elif format_type == "by_prefix" and category == "artist":
                formatted_tags.append(f"by {tag.replace('_', ' ')}")
            elif format_type == "from_prefix" and category == "copyright":
                formatted_tags.append(f"from {tag.replace('_', ' ')}")
            elif format_type == "parentheses":
                formatted_tags.append(f"({tag})")
            elif format_type == "brackets":
                formatted_tags.append(f"[{tag}]")
            elif format_type == "underscores":
                formatted_tags.append(tag.replace(' ', '_'))
            else:
                formatted_tags.append(tag)
        
        return ", ".join(formatted_tags)
    
    def _combine_tags_in_order(self, tag_list, separator):
        """æŒ‰æ­£ç¡®é¡ºåºç»„åˆæ ‡ç­¾ï¼šArtist-Character-Copyright-General-Metadata"""
        # é€‰æ‹©åˆ†éš”ç¬¦
        sep_map = {"comma": ", ", "space": " ", "newline": "\n"}
        sep = sep_map.get(separator, ", ")
        
        result_parts = []
        for tags, include in tag_list:
            if include and tags:
                result_parts.append(tags)
        
        return sep.join(result_parts)
    
    def _empty_result(self, error_msg):
        """è¿”å›ç©ºç»“æœ"""
        return ("", "", "", "", "", "", "", error_msg)


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "GelbooruAccurateExtractor": GelbooruAccurateExtractor,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "GelbooruAccurateExtractor": "Gelbooru Accurate Extractor",
}
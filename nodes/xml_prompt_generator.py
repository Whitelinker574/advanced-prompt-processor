# -*- coding: utf-8 -*-
"""
XMLæç¤ºè¯ç”Ÿæˆå™¨ - å°†ç”¨æˆ·è¾“å…¥è½¬æ¢ä¸ºç»“æ„åŒ–XMLæ ¼å¼
ä½œè€…: whitelinker
ç‰ˆæœ¬: 2.1.1

æ–°å¢åŠŸèƒ½ï¼š
- ğŸŒ ä»£ç†æ”¯æŒï¼šè‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿä»£ç†æˆ–æ‰‹åŠ¨è®¾ç½®ä»£ç†
- ğŸ”§ æ™ºèƒ½è¿æ¥ï¼šæ”¯æŒ Gemini API æ ¼å¼è‡ªåŠ¨è½¬æ¢
- ğŸ“Š è¯¦ç»†æ—¥å¿—ï¼šåŒ…å«ä»£ç†çŠ¶æ€å’Œè¿æ¥ä¿¡æ¯çš„å®Œæ•´æ—¥å¿—
- ğŸ›¡ï¸ é”™è¯¯å¤„ç†ï¼šå¢å¼ºçš„ç½‘ç»œè¿æ¥é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- ğŸ”„ ä»£ç†æ ¼å¼ï¼šè‡ªåŠ¨è½¬æ¢ httpx/requests ä»£ç†æ ¼å¼

ä»£ç†è®¾ç½®è¯´æ˜ï¼š
1. æ‰‹åŠ¨è®¾ç½®ï¼šåœ¨èŠ‚ç‚¹ä¸­å¡«å…¥ HTTP/HTTPS ä»£ç†åœ°å€
2. è‡ªåŠ¨æ£€æµ‹ï¼šç•™ç©ºè‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿç¯å¢ƒå˜é‡å’Œ Windows æ³¨å†Œè¡¨ä»£ç†è®¾ç½®
3. æ”¯æŒæ ¼å¼ï¼šhttp://127.0.0.1:7890 æˆ– https://proxy.example.com:8080
"""

import re
import json
import os
import requests
from typing import Dict, List, Any, Tuple
from urllib.parse import urlparse

# è·¨å¹³å°winregå¯¼å…¥
try:
    import winreg
    HAS_WINREG = True
except ImportError:
    HAS_WINREG = False


def get_system_proxy(manual_http_proxy="", manual_https_proxy=""):
    """è·å–ç³»ç»Ÿä»£ç†è®¾ç½®ï¼Œæ”¯æŒæ‰‹åŠ¨è®¾ç½®"""
    try:
        # ä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨è®¾ç½®çš„ä»£ç†
        if manual_http_proxy or manual_https_proxy:
            proxies = {}
            if manual_http_proxy:
                proxies['http'] = manual_http_proxy
            if manual_https_proxy:
                proxies['https'] = manual_https_proxy
            return proxies
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        http_proxy = os.environ.get('HTTP_PROXY') or os.environ.get('http_proxy')
        https_proxy = os.environ.get('HTTPS_PROXY') or os.environ.get('https_proxy')
        
        if http_proxy or https_proxy:
            return {'http': http_proxy, 'https': https_proxy}
        
        # Windowsæ³¨å†Œè¡¨æ£€æµ‹ (ä»…Windows)
        if HAS_WINREG:
            try:
                reg_key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, 
                                        r"Software\Microsoft\Windows\CurrentVersion\Internet Settings")
                proxy_enable = winreg.QueryValueEx(reg_key, "ProxyEnable")[0]
                if proxy_enable:
                    proxy_server = winreg.QueryValueEx(reg_key, "ProxyServer")[0]
                    winreg.CloseKey(reg_key)
                    proxy_url = f"http://{proxy_server}"
                    return {'http': proxy_url, 'https': proxy_url}
                else:
                    winreg.CloseKey(reg_key)
            except:
                pass
    except:
        pass
    
    return None

class XMLPromptGenerator:
    """
    XMLæç¤ºè¯ç”Ÿæˆå™¨
    å°†ç”¨æˆ·è¾“å…¥é€šè¿‡LLMè½¬æ¢ä¸ºç»“æ„åŒ–çš„XMLæ ¼å¼ï¼Œå¹¶æ”¯æŒç¬¦å·å¼ºåŒ–
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "user_input": ("STRING", {
                    "multiline": True,
                    "default": "", 
                    "placeholder": "è¾“å…¥æ ‡ç­¾æˆ–è‡ªç„¶è¯­è¨€æè¿°"
                }),
                "input_type": (["tags", "description"], {
                    "default": "description",
                    "tooltip": "è¾“å…¥ç±»å‹ï¼štags(æ ‡ç­¾) æˆ– description(è‡ªç„¶è¯­è¨€æè¿°)"
                }),
                "api_url": ("STRING", {
                    "default": "https://api.openai.com/v1/chat/completions",
                    "placeholder": "APIåœ°å€"
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "placeholder": "APIå¯†é’¥"
                }),
                "model_name": ("STRING", {
                    "default": "gpt-3.5-turbo",
                    "placeholder": "æ¨¡å‹åç§°ï¼ˆGeminiè¯·ä½¿ç”¨: gemini-2.5-flash, gemini-2.0-flash-001 æˆ– gemini-1.5-proï¼‰"
                }),
            },
            "optional": {
                "enable_symbol_enhancement": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "å¯ç”¨ç¬¦å·å¼ºåŒ–ï¼ˆ@ç”»å¸ˆ, #è§’è‰²ç­‰ï¼‰"
                }),
                "character_count": ("INT", {
                    "default": 1,
                    "min": 1,
                    "max": 5,
                    "tooltip": "è§’è‰²æ•°é‡"
                }),
                "proxy_http": ("STRING", {
                    "default": "",
                    "placeholder": "HTTPä»£ç†åœ°å€(å¦‚: http://127.0.0.1:7890)ï¼Œç•™ç©ºè‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿä»£ç†"
                }),
                "proxy_https": ("STRING", {
                    "default": "",
                    "placeholder": "HTTPSä»£ç†åœ°å€(å¦‚: http://127.0.0.1:7890)ï¼Œç•™ç©ºè‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿä»£ç†"
                }),
            },
        }
    
    RETURN_TYPES = ("STRING", "STRING", "STRING", "STRING")
    RETURN_NAMES = ("xml_output", "final_prompt", "processing_log", "raw_llm_response")
    FUNCTION = "generate_xml_prompt"
    CATEGORY = "Advanced Prompt Processor"
    
    def __init__(self):
        self.prefix = "You are an assistant designed to generate anime images based on textual prompts. <Prompt Start> "
        
        # XMLæ¨¡æ¿ç»“æ„
        self.xml_template = {
            "character": {
                "name": "",
                "gender": "",
                "appearance": "",
                "clothing": "",
                "body_type": "",
                "expression": "",
                "action": "",
                "interaction": "",
                "position": ""
            },
            "general_tags": {
                "count": "",
                "artists": "",
                "style": "",
                "background": "",
                "environment": "",
                "perspective": "",
                "atmosphere": "",
                "lighting": "",
                "quality": "",
                "objects": "",
                "other": ""
            }
        }

    def clean_and_validate_url(self, url: str) -> str:
        """æ¸…ç†å’ŒéªŒè¯API URL"""
        if not url:
            raise ValueError("API URLä¸èƒ½ä¸ºç©º")
        
        # å»é™¤é¦–å°¾ç©ºæ ¼
        clean_url = url.strip()
        
        # éªŒè¯URLæ ¼å¼
        try:
            parsed = urlparse(clean_url)
            if not parsed.scheme or not parsed.netloc:
                raise ValueError(f"æ— æ•ˆçš„URLæ ¼å¼: {clean_url}")
        except Exception as e:
            raise ValueError(f"URLè§£æå¤±è´¥: {clean_url}, é”™è¯¯: {str(e)}")
        
        return clean_url

    def get_xml_conversion_prompt(self) -> str:
        """è·å–XMLè½¬æ¢çš„LLMæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŠ¨æ¼«å›¾åƒç”Ÿæˆæ ‡ç­¾å¤„ç†ä¸“å®¶ã€‚è¯·å°†ç”¨æˆ·è¾“å…¥è½¬æ¢ä¸ºç»“æ„åŒ–çš„XMLæ ¼å¼ã€‚

XMLæ ¼å¼è¦æ±‚:
1. è§’è‰²ä¿¡æ¯ <character_1>
   - <name>: è§’è‰²åç§°ï¼ˆå¦‚hatsune_mikuï¼‰
   - <gender>: æ€§åˆ«å’Œæ•°é‡ï¼ˆå¦‚1girl, 1boyï¼‰
   - <appearance>: å¤–è§‚ç‰¹å¾ï¼ˆå¤´å‘ã€çœ¼ç›ã€èº«ä½“ç‰¹å¾ï¼‰
   - <clothing>: æœè£…æè¿°
   - <body_type>: èº«ä½“ç±»å‹å’Œç‰¹æ®Šæ ‡è®°
   - <expression>: è¡¨æƒ…
   - <action>: åŠ¨ä½œ
   - <interaction>: äº’åŠ¨
   - <position>: ä½ç½®å’Œè§’åº¦

2. é€šç”¨æ ‡ç­¾ <general_tags>
   - <count>: äººæ•°ç»Ÿè®¡
   - <artists>: ç”»å¸ˆé£æ ¼ï¼ˆæ ¼å¼ï¼š@artist_name:æƒé‡ï¼‰
   - <style>: ç”»é£å’Œç¾å­¦
   - <background>: èƒŒæ™¯
   - <environment>: ç¯å¢ƒå…ƒç´ 
   - <perspective>: è§†è§’
   - <atmosphere>: æ°›å›´
   - <lighting>: å…‰ç…§
   - <quality>: è´¨é‡æ ‡ç­¾
   - <objects>: ç‰©ä½“
   - <other>: å…¶ä»–

æ³¨æ„äº‹é¡¹:
- æ‰€æœ‰æ ‡ç­¾ç”¨è‹±æ–‡ï¼Œç”¨é€—å·åˆ†éš”
- ç”»å¸ˆåç§°å‰åŠ @ç¬¦å·
- ç©ºçš„ç±»åˆ«ä¿ç•™ç©ºæ ‡ç­¾
- ç¡®ä¿XMLæ ¼å¼æ­£ç¡®
- åªè¿”å›XMLå†…å®¹ï¼Œä¸è¦å…¶ä»–è§£é‡Š

ç¤ºä¾‹è¾“å‡º:
<character_1>
<name>hatsune_miku</name>
<gender>1girl</gender>
<appearance>long_hair, blue_hair, blue_eyes</appearance>
<clothing>detached_sleeves, necktie, skirt</clothing>
<body_type></body_type>
<expression>smile</expression>
<action>looking_at_viewer</action>
<interaction></interaction>
<position></position>
</character_1>

<general_tags>
<count>1girl, solo</count>
<artists>@wlop, @artgerm</artists>
<style>very_aesthetic, detailed</style>
<background></background>
<environment></environment>
<perspective></perspective>
<atmosphere></atmosphere>
<lighting></lighting>
<quality>masterpiece, best_quality</quality>
<objects></objects>
<other></other>
</general_tags>"""

    def call_openai_api(self, api_key: str, model: str, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨OpenAI API"""
        try:
            import openai
            client = openai.OpenAI(api_key=api_key)
            
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=2000,
                temperature=0.3
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"OpenAI APIè°ƒç”¨å¤±è´¥: {str(e)}"

    def call_claude_api(self, api_key: str, model: str, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨Claude API"""
        try:
            import anthropic
            client = anthropic.Anthropic(api_key=api_key)
            
            response = client.messages.create(
                model=model,
                max_tokens=2000,
                temperature=0.3,
                system=system_prompt,
                messages=[
                    {"role": "user", "content": user_prompt}
                ]
            )
            
            return response.content[0].text.strip()
            
        except Exception as e:
            return f"Claude APIè°ƒç”¨å¤±è´¥: {str(e)}"

    def call_gemini_api(self, api_key: str, model: str, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨Gemini API"""
        try:
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            
            gemini_model = genai.GenerativeModel(model)
            combined_prompt = f"{system_prompt}\n\nç”¨æˆ·è¾“å…¥ï¼š{user_prompt}"
            
            response = gemini_model.generate_content(
                combined_prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=2000,
                    temperature=0.3,
                )
            )
            
            return response.text.strip()
            
        except Exception as e:
            return f"Gemini APIè°ƒç”¨å¤±è´¥: {str(e)}"

    def call_deepseek_api(self, api_key: str, model: str, system_prompt: str, user_prompt: str, proxies=None) -> str:
        """è°ƒç”¨DeepSeek APIï¼Œæ”¯æŒä»£ç†"""
        try:
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "stream": False,
                "max_tokens": 2000,
                "temperature": 0.3
            }
            
            response = requests.post("https://api.deepseek.com/chat/completions", 
                                   headers=headers, json=data, proxies=proxies, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
            
        except Exception as e:
            return f"DeepSeek APIè°ƒç”¨å¤±è´¥: {str(e)}"

    def call_custom_api(self, api_url: str, api_key: str, model: str, system_prompt: str, user_prompt: str, proxies=None) -> str:
        """è°ƒç”¨è‡ªå®šä¹‰APIï¼Œæ”¯æŒä»£ç†"""
        try:
            # æ¸…ç†å’ŒéªŒè¯API URL
            clean_api_url = self.clean_and_validate_url(api_url)
            
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "stream": False,
                "max_tokens": 2000,
                "temperature": 0.3
            }
            
            response = requests.post(clean_api_url, headers=headers, json=data, 
                                   proxies=proxies, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
            
        except Exception as e:
            return f"è‡ªå®šä¹‰APIè°ƒç”¨å¤±è´¥: {str(e)}"

    def call_llm_api(self, ai_model: str, api_key: str, model_name: str, system_prompt: str, user_prompt: str, custom_api_url: str = "") -> str:
        """ç»Ÿä¸€çš„LLM APIè°ƒç”¨æ¥å£"""
        if not api_key:
            return "APIå¯†é’¥æœªè®¾ç½®"
        
        if ai_model == "openai":
            return self.call_openai_api(api_key, model_name, system_prompt, user_prompt)
        elif ai_model == "claude":
            return self.call_claude_api(api_key, model_name, system_prompt, user_prompt)
        elif ai_model == "gemini":
            return self.call_gemini_api(api_key, model_name, system_prompt, user_prompt)
        elif ai_model == "deepseek":
            return self.call_deepseek_api(api_key, model_name, system_prompt, user_prompt)
        elif ai_model == "custom":
            if not custom_api_url:
                return "è‡ªå®šä¹‰æ¨¡å¼éœ€è¦æä¾›API URL"
            return self.call_custom_api(custom_api_url, api_key, model_name, system_prompt, user_prompt)
        else:
            return f"ä¸æ”¯æŒçš„AIæ¨¡å‹: {ai_model}"



    def call_simple_llm_api(self, api_url: str, api_key: str, model: str, system_prompt: str, user_prompt: str, proxy_http: str = "", proxy_https: str = "") -> str:
        """ç®€åŒ–çš„LLM APIè°ƒç”¨ï¼Œæ”¯æŒGeminiè‡ªåŠ¨æ ¼å¼è½¬æ¢å’Œä»£ç†"""
        try:
            # æ¸…ç†å’ŒéªŒè¯API URL
            clean_api_url = self.clean_and_validate_url(api_url)
            
            # è·å–ä»£ç†è®¾ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨è®¾ç½®ï¼‰
            proxies = get_system_proxy(proxy_http, proxy_https)
            
            # æ£€æµ‹Gemini APIå¹¶è‡ªåŠ¨è½¬æ¢æ ¼å¼
            if "generativelanguage.googleapis.com" in clean_api_url or "gemini" in model.lower():
                return self._call_gemini_xml_api(api_key, model, system_prompt, user_prompt, proxies)
            
            # æ ‡å‡†çš„OpenAIå…¼å®¹APIè°ƒç”¨
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "stream": False,
                "max_tokens": 2000,
                "temperature": 0.3
            }
            
            response = requests.post(clean_api_url, headers=headers, json=data, 
                                   proxies=proxies, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
            
        except requests.exceptions.Timeout:
            return "XMLç”ŸæˆAPIè°ƒç”¨è¶…æ—¶"
        except Exception as e:
            return f"APIè°ƒç”¨å¤±è´¥: {str(e)}"
    
    def _call_gemini_xml_api(self, api_key: str, model: str, system_prompt: str, user_prompt: str, proxies=None) -> str:
        """ç®€åŒ–çš„Gemini XML APIè°ƒç”¨ï¼Œå‚è€ƒ gemini_nodes.py çš„æ­£ç¡®å®ç°"""
        try:
            # éªŒè¯å’Œä¿®æ­£æ¨¡å‹åç§°
            corrected_model = self._validate_gemini_model_name(model)
            
            try:
                # ä½¿ç”¨å’Œ gemini_nodes.py ç›¸åŒçš„è°ƒç”¨æ–¹å¼
                import httpx
                
                # è½¬æ¢ä»£ç†æ ¼å¼ä¸º httpx å…¼å®¹æ ¼å¼
                httpx_proxies = None
                if proxies:
                    httpx_proxies = {}
                    if 'http' in proxies and proxies['http']:
                        httpx_proxies['http://'] = proxies['http']
                    if 'https' in proxies and proxies['https']:
                        httpx_proxies['https://'] = proxies['https']
                    print(f"ğŸŒ XMLç”Ÿæˆå™¨ä½¿ç”¨ä»£ç† (httpxæ ¼å¼): {httpx_proxies}")
                else:
                    print("ğŸŒ XMLç”Ÿæˆå™¨æœªä½¿ç”¨ä»£ç†")
                
                client = httpx.Client(
                    base_url="https://generativelanguage.googleapis.com",
                    params={'key': api_key},
                    proxies=httpx_proxies,
                    timeout=30
                )
                
                try:
                    # ç»„åˆæç¤ºè¯
                    combined_prompt = f"{system_prompt}\n\nç”¨æˆ·è¯·æ±‚ï¼š{user_prompt}"
                    
                    body = {
                        "contents": [{
                            "parts": [{
                                "text": combined_prompt
                            }]
                        }],
                        "generationConfig": {
                            "maxOutputTokens": 2000,
                            "temperature": 0.3,
                            "stopSequences": [],
                            "candidateCount": 1
                        }
                    }
                    
                    endpoint = f"/v1beta/models/{corrected_model}:generateContent"
                    response = client.post(endpoint, json=body)
                    
                    # å¢å¼ºé”™è¯¯å¤„ç†
                    if response.status_code == 400:
                        error_detail = ""
                        try:
                            error_json = response.json()
                            error_detail = error_json.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                        except:
                            error_detail = f"HTTP 400 - è¯·æ£€æŸ¥æ¨¡å‹åç§°å’Œ API å¯†é’¥"
                        return f"Gemini XML APIè¯·æ±‚é”™è¯¯: {error_detail}"
                    
                    response.raise_for_status()
                    
                    result = response.json()
                    
                    if 'candidates' in result and len(result['candidates']) > 0:
                        candidate = result['candidates'][0]
                        if 'content' in candidate and 'parts' in candidate['content']:
                            parts = candidate['content']['parts']
                            if len(parts) > 0 and 'text' in parts[0]:
                                return parts[0]['text'].strip()
                    
                    return "Gemini XML APIå“åº”æ ¼å¼å¼‚å¸¸"
                    
                finally:
                    client.close()
                    
            except ImportError:
                # å¦‚æœ httpx ä¸å¯ç”¨ï¼Œå›é€€åˆ° requests æ–¹æ³•
                corrected_model = self._validate_gemini_model_name(model)
                
                # ä¿®æ­£ï¼šAPI å¯†é’¥é€šè¿‡ URL å‚æ•°ä¼ é€’ï¼Œè€Œä¸æ˜¯ header
                api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{corrected_model}:generateContent?key={api_key}"
                
                headers = {
                    "Content-Type": "application/json"
                }
                
                # ç»„åˆæç¤ºè¯
                combined_prompt = f"{system_prompt}\n\nç”¨æˆ·è¯·æ±‚ï¼š{user_prompt}"
                
                data = {
                    "contents": [{
                        "parts": [{
                            "text": combined_prompt
                        }]
                    }],
                    "generationConfig": {
                        "maxOutputTokens": 2000,
                        "temperature": 0.3,
                        "stopSequences": [],
                        "candidateCount": 1
                    }
                }
                
                response = requests.post(api_url, headers=headers, json=data, 
                                       proxies=proxies, timeout=30)
                
                # å¢å¼ºé”™è¯¯å¤„ç†
                if response.status_code == 400:
                    error_detail = ""
                    try:
                        error_json = response.json()
                        error_detail = error_json.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                    except:
                        error_detail = f"HTTP 400 - è¯·æ£€æŸ¥æ¨¡å‹åç§°å’Œ API å¯†é’¥"
                    return f"Gemini XML APIè¯·æ±‚é”™è¯¯: {error_detail}"
                
                response.raise_for_status()
                
                result = response.json()
                
                if 'candidates' in result and len(result['candidates']) > 0:
                    candidate = result['candidates'][0]
                    if 'content' in candidate and 'parts' in candidate['content']:
                        parts = candidate['content']['parts']
                        if len(parts) > 0 and 'text' in parts[0]:
                            return parts[0]['text'].strip()
                
                return "Gemini XML APIå“åº”æ ¼å¼å¼‚å¸¸"
            
        except Exception as e:
            return f"Gemini XML APIè°ƒç”¨å¤±è´¥: {str(e)}"
    
    def _validate_gemini_model_name(self, model: str) -> str:
        """éªŒè¯å’Œä¿®æ­£ Gemini æ¨¡å‹åç§°"""
        # å¸¸è§çš„æ­£ç¡®æ¨¡å‹åç§°æ˜ å°„ï¼ˆæ›´æ–°æ”¯æŒ gemini-2.5-flashï¼‰
        model_mapping = {
            "gemini-2.0-flash": "gemini-2.0-flash-001", 
            "gemini-flash": "gemini-2.0-flash-001",
            "gemini-1.5-pro": "gemini-1.5-pro",
            "gemini-pro": "gemini-1.5-pro",
            "gemini-1.5-flash": "gemini-1.5-flash",
            # gemini-2.5-flash åº”è¯¥æ˜¯æœ‰æ•ˆçš„ï¼Œä¸éœ€è¦æ˜ å°„
        }
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿®æ­£
        if model in model_mapping:
            corrected = model_mapping[model]
            print(f"ğŸ”§ XMLç”Ÿæˆå™¨-Geminiæ¨¡å‹åç§°ä¿®æ­£: {model} -> {corrected}")
            return corrected
        
        # å¦‚æœæ¨¡å‹åå·²ç»æ­£ç¡®æˆ–æœªçŸ¥ï¼Œç›´æ¥è¿”å›
        return model

    def apply_symbol_enhancement(self, xml_content: str) -> str:
        """å¯¹XMLå†…å®¹åº”ç”¨ç¬¦å·å¼ºåŒ–ï¼Œä¸advanced_prompt_processor.pyæ ¼å¼ä¸€è‡´"""
        enhanced_content = xml_content
        
        # å¯¹ç”»å¸ˆæ ‡ç­¾åº”ç”¨@ç¬¦å·å¼ºåŒ–
        def enhance_artists(match):
            artists_content = match.group(1)
            if not artists_content.strip():
                return match.group(0)
            
            # åˆ†å‰²ç”»å¸ˆå¹¶æ·»åŠ @ç¬¦å·
            artists = [artist.strip() for artist in artists_content.split(',')]
            enhanced_artists = []
            
            for artist in artists:
                if artist:
                    # å¦‚æœå·²ç»æœ‰@ç¬¦å·ï¼Œä¿æŒä¸å˜
                    if artist.startswith('@'):
                        enhanced_artists.append(artist)
                    else:
                        # æ¸…ç†ç”»å¸ˆæ ‡ç­¾æ ¼å¼
                        clean_tag = artist
                        if clean_tag.startswith("by "):
                            clean_tag = clean_tag[3:]
                        elif "artist:" in clean_tag:
                            clean_tag = clean_tag.replace("artist:", "")
                        
                        # å¤„ç†æƒé‡æ ¼å¼
                        if ':' in clean_tag:
                            name, weight = clean_tag.split(':', 1)
                            # å°†ç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼Œå¹¶æ·»åŠ @å‰ç¼€
                            enhanced_tag = "@" + name.strip().replace(" ", "_") + ":" + weight.strip()
                            enhanced_artists.append(enhanced_tag)
                        else:
                            # å°†ç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼Œå¹¶æ·»åŠ @å‰ç¼€
                            enhanced_tag = "@" + clean_tag.replace(" ", "_")
                            enhanced_artists.append(enhanced_tag)
            
            return f"<artists>{', '.join(enhanced_artists)}</artists>"
        
        # åº”ç”¨ç”»å¸ˆå¼ºåŒ–
        enhanced_content = re.sub(r'<artists>(.*?)</artists>', enhance_artists, enhanced_content, flags=re.DOTALL)
        
        # å¯¹è§’è‰²åç§°å’Œè§’è‰²å¤–è§‚ç­‰åº”ç”¨#ç¬¦å·å¼ºåŒ–
        def enhance_characters(match):
            characters_content = match.group(1)
            if not characters_content.strip():
                return match.group(0)
            
            # åˆ†å‰²è§’è‰²å¹¶æ·»åŠ #ç¬¦å·
            characters = [char.strip() for char in characters_content.split(',')]
            enhanced_characters = []
            
            for char in characters:
                if char:
                    # å¦‚æœå·²ç»æœ‰#ç¬¦å·ï¼Œä¿æŒä¸å˜
                    if char.startswith('#'):
                        enhanced_characters.append(char)
                    else:
                        # å°†ç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼Œå¹¶æ·»åŠ #å‰ç¼€
                        enhanced_tag = "#" + char.replace(" ", "_")
                        enhanced_characters.append(enhanced_tag)
            
            return f"<name>{', '.join(enhanced_characters)}</name>"
        
        # åº”ç”¨è§’è‰²åç§°å¼ºåŒ–
        enhanced_content = re.sub(r'<name>(.*?)</name>', enhance_characters, enhanced_content, flags=re.DOTALL)
        
        return enhanced_content

    def xml_to_final_prompt(self, xml_content: str) -> str:
        """å°†XMLå†…å®¹è½¬æ¢ä¸ºæœ€ç»ˆçš„æç¤ºè¯æ ¼å¼"""
        try:
            # æå–XMLä¸­çš„æ‰€æœ‰å†…å®¹
            all_tags = []
            
            # æå–æ‰€æœ‰XMLæ ‡ç­¾ä¸­çš„å†…å®¹
            xml_pattern = r'<([^>]+)>(.*?)</\1>'
            matches = re.findall(xml_pattern, xml_content, re.DOTALL)
            
            for tag_name, content in matches:
                content = content.strip()
                if content:
                    all_tags.append(content)
            
            # åˆå¹¶æ‰€æœ‰æ ‡ç­¾
            final_content = ', '.join(all_tags)
            
            # æ·»åŠ å›ºå®šå‰ç¼€
            return self.prefix + final_content
            
        except Exception as e:
            return f"{self.prefix}XMLè§£æå¤±è´¥: {str(e)}"

    def generate_xml_prompt(self, user_input: str, input_type: str, api_url: str, api_key: str, model_name: str,
                           enable_symbol_enhancement: bool = True, character_count: int = 1,
                           proxy_http: str = "", proxy_https: str = "") -> Tuple[str, str, str, str]:
        """ç”ŸæˆXMLæ ¼å¼çš„æç¤ºè¯"""
        
        log_entries = []
        log_entries.append("=== XMLæç¤ºè¯ç”Ÿæˆå¼€å§‹ ===")
        log_entries.append(f"è¾“å…¥ç±»å‹: {input_type}")
        log_entries.append(f"APIåœ°å€: {api_url}")
        log_entries.append(f"æ¨¡å‹: {model_name}")
        log_entries.append(f"ç¬¦å·å¼ºåŒ–: {'å¯ç”¨' if enable_symbol_enhancement else 'ç¦ç”¨'}")
        log_entries.append(f"è§’è‰²æ•°é‡: {character_count}")
        
        # è®°å½•ä»£ç†è®¾ç½®
        if proxy_http or proxy_https:
            log_entries.append(f"ğŸŒ æ‰‹åŠ¨ä»£ç†è®¾ç½® - HTTP: {proxy_http or 'æ— '}, HTTPS: {proxy_https or 'æ— '}")
        else:
            log_entries.append("ğŸŒ å°†è‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿä»£ç†è®¾ç½®")
        
        if not user_input.strip():
            error_msg = "ç”¨æˆ·è¾“å…¥ä¸ºç©º"
            log_entries.append(f"âŒ {error_msg}")
            return self.prefix, self.prefix, "\n".join(log_entries), error_msg
        
        if not api_key:
            error_msg = "APIå¯†é’¥æœªè®¾ç½®"
            log_entries.append(f"âŒ {error_msg}")
            return self.prefix, self.prefix, "\n".join(log_entries), error_msg
        
        # å‡†å¤‡LLMæç¤º
        system_prompt = self.get_xml_conversion_prompt()
        
        if input_type == "tags":
            user_prompt = f"è¯·å°†ä»¥ä¸‹æ ‡ç­¾è½¬æ¢ä¸ºXMLæ ¼å¼ï¼š\n{user_input}"
        else:
            user_prompt = f"è¯·å°†ä»¥ä¸‹è‡ªç„¶è¯­è¨€æè¿°è½¬æ¢ä¸ºXMLæ ¼å¼ï¼š\n{user_input}"
        
        # å¦‚æœéœ€è¦å¤šä¸ªè§’è‰²ï¼Œåœ¨æç¤ºä¸­è¯´æ˜
        if character_count > 1:
            user_prompt += f"\n\næ³¨æ„ï¼šéœ€è¦ç”Ÿæˆ{character_count}ä¸ªè§’è‰²ï¼Œè¯·åˆ†åˆ«ç”¨<character_1>, <character_2>ç­‰æ ‡ç­¾ã€‚"
        
        log_entries.append("ğŸ¤– è°ƒç”¨LLMè¿›è¡ŒXMLè½¬æ¢...")
        
        # è°ƒç”¨LLM API
        llm_response = self.call_simple_llm_api(api_url, api_key, model_name, system_prompt, user_prompt, proxy_http, proxy_https)
        
        if llm_response.startswith(("APIè°ƒç”¨å¤±è´¥", "å¤„ç†å¤±è´¥", "ä¸æ”¯æŒçš„AIæ¨¡å‹")):
            log_entries.append(f"âŒ LLMè°ƒç”¨å¤±è´¥: {llm_response}")
            return self.prefix, self.prefix, "\n".join(log_entries), llm_response
        
        log_entries.append("âœ… LLMè°ƒç”¨æˆåŠŸ")
        
        # æå–å’Œæ¸…ç†XMLå†…å®¹
        xml_content = llm_response.strip()
        
        # ç¡®ä¿XMLæ ¼å¼æ­£ç¡®
        if not ("<character_" in xml_content and "<general_tags>" in xml_content):
            log_entries.append("âš ï¸ LLMè¿”å›çš„æ ¼å¼å¯èƒ½ä¸å®Œæ•´ï¼Œå°è¯•ä¿®å¤...")
            # è¿™é‡Œå¯ä»¥æ·»åŠ ä¸€äº›åŸºæœ¬çš„ä¿®å¤é€»è¾‘
        
        # åº”ç”¨ç¬¦å·å¼ºåŒ–
        if enable_symbol_enhancement:
            xml_content = self.apply_symbol_enhancement(xml_content)
            log_entries.append("âœ… ç¬¦å·å¼ºåŒ–å®Œæˆï¼ˆ@ç”»å¸ˆ, #è§’è‰²ï¼‰")
        
        # ä¸ºXMLè¾“å‡ºæ·»åŠ å‰ç¼€
        xml_output_with_prefix = self.prefix + "\n" + xml_content
        
        # è½¬æ¢ä¸ºæœ€ç»ˆæç¤ºè¯
        final_prompt = self.xml_to_final_prompt(xml_content)
        log_entries.append("âœ… æœ€ç»ˆæç¤ºè¯ç”Ÿæˆå®Œæˆ")
        
        log_entries.append("=== XMLæç¤ºè¯ç”Ÿæˆå®Œæˆ ===")
        processing_log = "\n".join(log_entries)
        
        return xml_output_with_prefix, final_prompt, processing_log, llm_response


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "XMLPromptGenerator": XMLPromptGenerator,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "XMLPromptGenerator": "XMLæç¤ºè¯ç”Ÿæˆå™¨",
}
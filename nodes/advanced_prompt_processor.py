# -*- coding: utf-8 -*-
"""
é«˜çº§æç¤ºè¯å¤„ç†å™¨ - ç»¼åˆå¤„ç†èŠ‚ç‚¹
æ•´åˆåˆ†ç±»ã€LLMå¢å¼ºã€æ ¼å¼åŒ–ç­‰åŠŸèƒ½

æ–°å¢åŠŸèƒ½ï¼š
- ğŸŒ ä»£ç†æ”¯æŒï¼šè‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿä»£ç†æˆ–æ‰‹åŠ¨è®¾ç½®ä»£ç†
- ğŸ”§ æ™ºèƒ½è¿æ¥ï¼šæ”¯æŒ Gemini API æ ¼å¼è‡ªåŠ¨è½¬æ¢
- ğŸ“Š è¯¦ç»†æ—¥å¿—ï¼šåŒ…å«ä»£ç†çŠ¶æ€å’Œè¿æ¥ä¿¡æ¯çš„å®Œæ•´æ—¥å¿—
- ğŸ›¡ï¸ é”™è¯¯å¤„ç†ï¼šå¢å¼ºçš„ç½‘ç»œè¿æ¥é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- ğŸ”„ ä»£ç†æ ¼å¼ï¼šè‡ªåŠ¨è½¬æ¢ httpx/requests ä»£ç†æ ¼å¼

ä»£ç†è®¾ç½®è¯´æ˜ï¼š
1. æ‰‹åŠ¨è®¾ç½®ï¼šåœ¨èŠ‚ç‚¹ä¸­å¡«å…¥ HTTP/HTTPS ä»£ç†åœ°å€
2. è‡ªåŠ¨æ£€æµ‹ï¼šç•™ç©ºè‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿç¯å¢ƒå˜é‡å’Œ Windows æ³¨å†Œè¡¨ä»£ç†è®¾ç½®
3. æ”¯æŒæ ¼å¼ï¼šhttp://127.0.0.1:7890 æˆ– https://proxy.example.com:8080
"""
import re
import json
import os
import requests
from typing import Dict, List, Any, Tuple
from requests.exceptions import RequestException
from urllib.parse import urlparse

# è·¨å¹³å°winregå¯¼å…¥
try:
    import winreg
    HAS_WINREG = True
except ImportError:
    HAS_WINREG = False


def get_system_proxy(manual_http_proxy="", manual_https_proxy=""):
    """è·å–ç³»ç»Ÿä»£ç†è®¾ç½®ï¼Œæ”¯æŒæ‰‹åŠ¨è®¾ç½®"""
    try:
        # ä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨è®¾ç½®çš„ä»£ç†
        if manual_http_proxy or manual_https_proxy:
            proxies = {}
            if manual_http_proxy:
                proxies['http'] = manual_http_proxy
            if manual_https_proxy:
                proxies['https'] = manual_https_proxy
            return proxies
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        http_proxy = os.environ.get('HTTP_PROXY') or os.environ.get('http_proxy')
        https_proxy = os.environ.get('HTTPS_PROXY') or os.environ.get('https_proxy')
        
        if http_proxy or https_proxy:
            return {'http': http_proxy, 'https': https_proxy}
        
        # Windowsæ³¨å†Œè¡¨æ£€æµ‹ (ä»…Windows)
        if HAS_WINREG:
            try:
                reg_key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, 
                                        r"Software\Microsoft\Windows\CurrentVersion\Internet Settings")
                proxy_enable = winreg.QueryValueEx(reg_key, "ProxyEnable")[0]
                if proxy_enable:
                    proxy_server = winreg.QueryValueEx(reg_key, "ProxyServer")[0]
                    winreg.CloseKey(reg_key)
                    proxy_url = f"http://{proxy_server}"
                    return {'http': proxy_url, 'https': proxy_url}
                else:
                    winreg.CloseKey(reg_key)
            except:
                pass
    except:
        pass
    
    return None


class AdvancedPromptProcessor:
    """
    é«˜çº§æç¤ºè¯å¤„ç†å™¨ - ç»¼åˆå¤„ç†èŠ‚ç‚¹
    æ•´åˆæç¤ºè¯åˆ†ç±»ã€LLMå¢å¼ºã€æ ¼å¼åŒ–ç­‰å…¨æµç¨‹åŠŸèƒ½
    """
    
    # ç±»å˜é‡ï¼šå°†å†…ç½®æ ‡ç­¾æ•°æ®ç§»åˆ°ç±»çº§åˆ«ï¼Œé¿å…æ¯æ¬¡å®ä¾‹åŒ–é‡å¤åˆ›å»º
    _TAG_DATABASE = None
    _KNOWLEDGE_CACHE = {}
    _COMPILED_PATTERNS = None
    
    # å¸¸é‡å®šä¹‰
    KNOWLEDGE_BASE_PATH = "Tag knowledge"
    MAX_LOG_LENGTH = 100
    DEFAULT_TIMEOUT = 30
    SYMBOL_PREFIX_ARTIST = "@"
    SYMBOL_PREFIX_CHARACTER = "#"
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "danbooru_tags": ("STRING", {
                    "multiline": True, 
                    "default": "", 
                    "placeholder": "è¾“å…¥Danbooruæ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”"
                }),
                "drawing_theme": ("STRING", {
                    "multiline": True, 
                    "default": "", 
                    "placeholder": "ç»˜å›¾ä¸»é¢˜æç¤ºè¯ï¼ˆæè¿°ä½ æƒ³è¦çš„ç”»é¢å†…å®¹å’Œé£æ ¼ï¼‰"
                }),
                "api_url": ("STRING", {
                    "default": "https://api.openai.com/v1/chat/completions",
                    "placeholder": "APIåœ°å€"
                }),
                "api_key": ("STRING", {
                    "default": "",
                    "placeholder": "APIå¯†é’¥"
                }),
                "model_name": ("STRING", {
                    "default": "gpt-3.5-turbo",
                    "placeholder": "æ¨¡å‹åç§°ï¼ˆGeminiè¯·ä½¿ç”¨: gemini-2.5-flash, gemini-2.0-flash-001 æˆ– gemini-1.5-proï¼‰"
                }),
            },
            "optional": {
                "classification_mode": (["local_knowledge", "llm_classification"], {
                    "default": "local_knowledge"
                }),
                "custom_characters": ("STRING", {
                    "default": "", 
                    "placeholder": "è‡ªå®šä¹‰è§’è‰²ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œä¼šç›´æ¥æ·»åŠ åˆ°è¾“å‡ºä¸­"
                }),
                "custom_artists": ("STRING", {
                    "default": "", 
                    "placeholder": "è‡ªå®šä¹‰ç”»å¸ˆï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œä¼šç›´æ¥æ·»åŠ åˆ°è¾“å‡ºä¸­"
                }),
                "custom_copyrights": ("STRING", {
                    "default": "", 
                    "placeholder": "è‡ªå®šä¹‰ç‰ˆæƒä½œå“ï¼ˆé€—å·åˆ†éš”ï¼‰ï¼Œä¼šç›´æ¥æ·»åŠ åˆ°è¾“å‡ºä¸­"
                }),
                "enable_symbol_enhancement": ("BOOLEAN", {"default": True}),
                "proxy_http": ("STRING", {
                    "default": "",
                    "placeholder": "HTTPä»£ç†åœ°å€(å¦‚: http://127.0.0.1:7890)ï¼Œç•™ç©ºè‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿä»£ç†"
                }),
                "proxy_https": ("STRING", {
                    "default": "",
                    "placeholder": "HTTPSä»£ç†åœ°å€(å¦‚: http://127.0.0.1:7890)ï¼Œç•™ç©ºè‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿä»£ç†"
                }),
            },
        }
    
    RETURN_TYPES = ("STRING", "STRING", "STRING", "DICT", "STRING")
    RETURN_NAMES = ("final_prompt", "enhanced_description", "formatted_prompt", "classified_tags", "processing_log")
    FUNCTION = "process_prompt"
    CATEGORY = "AI/Advanced Prompt"
    
    @classmethod 
    def _init_tag_database(cls):
        """åˆå§‹åŒ–æ ‡ç­¾æ•°æ®åº“ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶åŠ è½½ï¼‰"""
        if cls._TAG_DATABASE is None:
            cls._TAG_DATABASE = {
            "special": {
                "1girl", "1boy", "1other", "2girls", "2boys", "3girls", "3boys", 
                "4girls", "4boys", "5girls", "5boys", "6+girls", "6+boys",
                "multiple girls", "multiple boys", "solo", "duo", "group"
            },
            "general": {
                # èº«ä½“éƒ¨ä½å’Œç‰¹å¾
                "long_hair", "short_hair", "medium_hair", "brown_hair", "black_hair", "blonde_hair", 
                "white_hair", "silver_hair", "grey_hair", "red_hair", "pink_hair", "purple_hair",
                "blue_hair", "green_hair", "orange_hair", "twintails", "ponytail", "braid", "braids",
                "blue_eyes", "brown_eyes", "green_eyes", "red_eyes", "yellow_eyes", "purple_eyes",
                "grey_eyes", "heterochromia", "closed_eyes", "one_eye_closed", "wink",
                
                # è¡¨æƒ…å’ŒåŠ¨ä½œ
                "smile", "open_mouth", "closed_mouth", "fang", "fangs", ":d", ":o", ":3",
                "blush", "sweat", "tears", "crying", "angry", "sad", "happy", "surprised",
                "looking_at_viewer", "looking_away", "looking_back", "looking_down", "looking_up",
                "sitting", "standing", "walking", "running", "lying", "kneeling", "crouching",
                "arms_up", "arms_behind_back", "hands_on_hips", "peace_sign", "v", "thumbs_up",
                
                # æœè£…å’Œé…é¥°
                "dress", "skirt", "shirt", "blouse", "sweater", "jacket", "coat", "hoodie",
                "pants", "shorts", "jeans", "stockings", "thighhighs", "socks", "pantyhose",
                "shoes", "boots", "sandals", "high_heels", "sneakers", "bare_feet",
                "hat", "cap", "headband", "hair_ornament", "hair_bow", "ribbon", "bow",
                "glasses", "sunglasses", "jewelry", "necklace", "earrings", "bracelet",
                "gloves", "fingerless_gloves", "mittens", "scarf", "tie", "necktie", "bowtie",
                "underwear", "panties", "bra", "bikini", "swimsuit", "lingerie",
                "school_uniform", "sailor_dress", "maid", "nurse", "police", "military",
                "kimono", "yukata", "chinese_clothes", "qipao", "cheongsam",
                "open_clothes", "open_shirt", "open_jacket", "torn_clothes",
                "robe", "cloak", "cape", "apron", "vest", "tank_top", "crop_top",
                
                # èº«ä½“ç‰¹å¾
                "horns", "tail", "wings", "ears", "animal_ears", "cat_ears", "fox_ears",
                "elf_ears", "pointed_ears", "long_ears", "fin_ears",
                "small_breasts", "medium_breasts", "large_breasts", "huge_breasts",
                "flat_chest", "cleavage", "sideboob", "underboob",
                "thick_thighs", "wide_hips", "slim", "curvy", "muscular",
                "pale_skin", "dark_skin", "tan", "dark_skinned_female",
                "scar", "bandages", "tattoo", "piercing",
                
                # æ‰‹å’ŒæŒ‡ç”²
                "fingernails", "long_fingernails", "sharp_fingernails", "colored_nails",
                "nail_polish", "nail_art", "black_nails", "red_nails", "blue_nails",
                "manicure", "claw_pose", "finger_gun", "pointing",
                
                # çœ¼ç›ç‰¹å¾
                "slit_pupils", "heart-shaped_pupils", "star-shaped_pupils", "cross-shaped_pupils",
                "glowing_eyes", "empty_eyes", "spiral_eyes", "x_x", "@_@",
                "eyelashes", "long_eyelashes", "thick_eyelashes", "makeup", "eyeshadow",
                "eyeliner", "mascara", "lipstick", "lip_gloss",
                
                # åœºæ™¯å’ŒèƒŒæ™¯
                "indoors", "outdoors", "bedroom", "bathroom", "kitchen", "living_room",
                "classroom", "school", "library", "office", "hospital", "park", "garden",
                "beach", "ocean", "forest", "mountain", "city", "street", "rooftop",
                "sky", "clouds", "sunset", "sunrise", "night", "starry_sky", "moon",
                "rain", "snow", "cherry_blossoms", "flowers", "trees", "grass",
                "building", "house", "bridge", "tower", "castle", "temple", "shrine",
                
                # ç‰©å“å’Œé“å…·
                "umbrella", "bag", "backpack", "book", "pen", "pencil", "paper",
                "phone", "computer", "laptop", "tablet", "camera", "microphone",
                "sword", "katana", "knife", "dagger", "gun", "rifle", "pistol",
                "shield", "armor", "helmet", "crown", "tiara", "staff", "wand",
                "ball", "balloon", "teddy_bear", "stuffed_animal", "doll",
                "food", "cake", "ice_cream", "coffee", "tea", "water", "bottle",
                "flower", "rose", "sunflower", "bouquet", "gift", "present",
                "mirror", "window", "door", "chair", "table", "bed", "pillow",
                "lamp", "candle", "fire", "flame", "smoke", "steam",
                
                # å§¿åŠ¿å’Œè§’åº¦
                "full_body", "upper_body", "lower_body", "portrait", "close-up",
                "from_above", "from_below", "from_side", "from_behind", "back_view",
                "profile", "three-quarter_view", "straight-on", "diagonal",
                "cowboy_shot", "dutch_angle", "bird's_eye_view", "worm's_eye_view"
            },
            "quality": {
                "masterpiece", "best quality", "high quality", "normal quality", "low quality",
                "worst quality", "jpeg artifacts", "signature", "watermark", "username",
                "blurry", "artist name", "trademark", "title", "bad anatomy", "bad hands",
                "text", "error", "missing fingers", "extra digit", "fewer digits",
                "cropped", "absurdres", "highres", "lowres"
            },
            "meta": {
                "realistic", "photorealistic", "photo", "cosplay", "real person",
                "official art", "promotional art", "scan", "magazine scan",
                "web", "pixiv", "twitter", "artstation", "deviantart", "tumblr"
            },
            "rating": {
                "rating:safe", "rating:questionable", "rating:explicit", "rating:sensitive",
                "safe", "sensitive", "questionable", "explicit", "nsfw", "sfw"
            }
        }
        
        return cls._TAG_DATABASE
    
    @classmethod
    def _init_patterns(cls):
        """åˆå§‹åŒ–ç¼–è¯‘åçš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼"""
        if cls._COMPILED_PATTERNS is None:
            import re
            cls._COMPILED_PATTERNS = {
                'character_patterns': [
                    re.compile(r"^\w+\s+\(\w+\)$"),  # è§’è‰²å (ä½œå“å)
                    re.compile(r"^\w+_\w+_\w+$"),    # ä¸‰æ®µå¼è§’è‰²å
                ],
                'non_character_patterns': [
                    re.compile(r".*_hair$"), re.compile(r".*_eyes$"), re.compile(r".*_clothes$"), 
                    re.compile(r".*_dress$"), re.compile(r".*_shirt$"), re.compile(r".*_mouth$"), 
                    re.compile(r".*_pupils$"), re.compile(r".*_polish$"), re.compile(r".*_art$"), 
                    re.compile(r".*_nails$"), re.compile(r".*_fingernails$"), re.compile(r".*_eyelashes$"), 
                    re.compile(r".*_makeup$"), re.compile(r".*_uniform$")
                ],
                'artist_patterns': [
                    re.compile(r"^by\s+\w+"),        # by ç”»å¸ˆå
                    re.compile(r"artist:\w+"),       # artist:ç”»å¸ˆå
                ]
            }
        return cls._COMPILED_PATTERNS
    
    @property
    def tag_database(self):
        """è·å–æ ‡ç­¾æ•°æ®åº“ï¼ˆæ‡’åŠ è½½ï¼‰"""
        return self._init_tag_database()
    
    @property  
    def copyright_keywords(self):
        """ç‰ˆæƒä½œå“å…³é”®è¯"""
        return {
            "vocaloid", "touhou", "fate", "pokemon", "naruto", "bleach", "one_piece",
            "dragon_ball", "attack_on_titan", "demon_slayer", "jujutsu_kaisen", 
            "genshin_impact", "honkai_impact", "azur_lane", "kantai_collection",
            "love_live", "idolmaster", "persona", "final_fantasy", "overwatch"
        }
    
    @property
    def character_patterns(self):
        """è·å–ç¼–è¯‘åçš„è§’è‰²åŒ¹é…æ¨¡å¼"""
        return self._init_patterns()['character_patterns']
    
    @property
    def non_character_patterns(self):
        """è·å–ç¼–è¯‘åçš„éè§’è‰²åŒ¹é…æ¨¡å¼"""
        return self._init_patterns()['non_character_patterns']
    
    @property
    def artist_patterns(self):
        """è·å–ç¼–è¯‘åçš„ç”»å¸ˆåŒ¹é…æ¨¡å¼"""
        return self._init_patterns()['artist_patterns']

    def __init__(self):
        # è½»é‡çº§åˆå§‹åŒ–
        self.debug_mode = False

    def safe_log(self, message: str, level: str = "info"):
        """å®‰å…¨çš„æ—¥å¿—è®°å½•æ–¹æ³•ï¼ˆä¸ºäº†å…¼å®¹æ€§ä¿ç•™ï¼Œå®é™…ä¸æ‰§è¡Œæ“ä½œï¼‰"""
        pass

    @staticmethod
    def clean_tag(tag: str) -> str:
        """ç»Ÿä¸€çš„æ ‡ç­¾æ¸…ç†å‡½æ•°"""
        return tag.strip().lower().replace(' ', '_')
    
    @staticmethod
    def parse_tags_from_string(text: str) -> list:
        """ä»æ–‡æœ¬ä¸­è§£ææ ‡ç­¾åˆ—è¡¨"""
        if not text.strip():
            return []
        return [AdvancedPromptProcessor.clean_tag(tag) for tag in text.split(',') if tag.strip()]
    
    def parse_custom_tags(self, custom_text: str) -> list:
        """è§£æè‡ªå®šä¹‰æ ‡ç­¾æ–‡æœ¬ï¼ˆé€—å·åˆ†éš”ï¼‰"""
        return self.parse_tags_from_string(custom_text)

    def clean_and_validate_url(self, url: str) -> str:
        """æ¸…ç†å’ŒéªŒè¯API URL"""
        if not url:
            raise ValueError("API URLä¸èƒ½ä¸ºç©º")
        
        # å»é™¤é¦–å°¾ç©ºæ ¼
        clean_url = url.strip()
        
        # éªŒè¯URLæ ¼å¼
        try:
            parsed = urlparse(clean_url)
            if not parsed.scheme or not parsed.netloc:
                raise ValueError(f"æ— æ•ˆçš„URLæ ¼å¼: {clean_url}")
        except Exception as e:
            raise ValueError(f"URLè§£æå¤±è´¥: {clean_url}, é”™è¯¯: {str(e)}")
        
        return clean_url

    def classify_tags(self, tags: str, custom_chars: set, custom_artists: set, custom_copyrights: set) -> Dict[str, List[str]]:
        """åˆ†ç±»æ ‡ç­¾"""
        tag_list = [tag.strip() for tag in tags.split(',') if tag.strip()]
        
        classified = {
            "special": [],
            "characters": [],
            "copyrights": [],
            "artists": [],
            "general": [],
            "quality": [],
            "meta": [],
            "rating": []
        }
        
        for tag in tag_list:
            category = self.classify_single_tag(tag, custom_chars, custom_artists, custom_copyrights)
            classified[category].append(tag)
        
        return classified

    def classify_single_tag(self, tag: str, custom_chars: set, custom_artists: set, custom_copyrights: set) -> str:
        """åˆ†ç±»å•ä¸ªæ ‡ç­¾"""
        tag_lower = tag.lower().strip()
        
        # æ£€æŸ¥é¢„å®šä¹‰ç±»åˆ«
        for category, tags in self.tag_database.items():
            if tag_lower in tags:
                return category
        
        # æ£€æŸ¥è‡ªå®šä¹‰æ ‡ç­¾
        if tag in custom_chars:
            return "characters"
        if tag in custom_artists:
            return "artists"
        if tag in custom_copyrights:
            return "copyrights"
        
        # æ£€æŸ¥ç‰ˆæƒå…³é”®è¯
        if tag_lower in self.copyright_keywords:
            return "copyrights"
        
        # é¦–å…ˆæ£€æŸ¥éè§’è‰²æ¨¡å¼ï¼Œé˜²æ­¢è¯¯åˆ†ç±»
        for pattern in self.non_character_patterns:
            if pattern.match(tag_lower):
                return "general"
        
        # åŸºäºæ¨¡å¼åŒ¹é…
        for pattern in self.character_patterns:
            if pattern.match(tag):
                return "characters"
        
        for pattern in self.artist_patterns:
            if pattern.match(tag):
                return "artists"
        
        return "general"

    def load_knowledge_base_from_folder(self, folder_path: str) -> Dict[str, Dict]:
        """ä»æ–‡ä»¶å¤¹åŠ è½½çŸ¥è¯†åº“ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        # æ£€æŸ¥ç¼“å­˜
        if folder_path in self._KNOWLEDGE_CACHE:
            return self._KNOWLEDGE_CACHE[folder_path]
        
        knowledge_base = self._load_knowledge_base_internal(folder_path)
        
        # ç¼“å­˜ç»“æœ
        self._KNOWLEDGE_CACHE[folder_path] = knowledge_base
        return knowledge_base
    
    def _load_knowledge_base_internal(self, folder_path: str) -> Dict[str, Dict]:
        """ä»æ–‡ä»¶å¤¹åŠ è½½çŸ¥è¯†åº“ï¼ˆè‡ªåŠ¨è¯»å–æ‰€æœ‰ç›¸å…³æ–‡ä»¶ï¼‰"""
        if not folder_path:
            return {}
        
        # ç¡®ä¿è·¯å¾„æ˜¯ç›¸å¯¹äºæ’ä»¶ç›®å½•çš„
        if not os.path.isabs(folder_path):
            plugin_dir = os.path.dirname(os.path.dirname(__file__))
            folder_path = os.path.join(plugin_dir, folder_path)
        
        if not os.path.exists(folder_path):
            self.safe_log(f"çŸ¥è¯†åº“æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}", "warning")
            return {}
        
        knowledge_base = {
            "special": set(),
            "characters": set(),
            "copyrights": set(),
            "artists": set(),
            "general": set(),
            "quality": set(),
            "meta": set(),
            "rating": set()
        }
        
        try:
            # é¢„å®šä¹‰çš„æ–‡ä»¶åæ˜ å°„
            category_files = {
                "special": ["special.csv", "äººæ•°æ ‡ç­¾.csv"],
                "characters": ["characters.csv", "è§’è‰².csv", "character.csv"],
                "copyrights": ["copyrights.csv", "ç‰ˆæƒ.csv", "copyright.csv"],
                "artists": ["artists.csv", "ç”»å¸ˆ.csv", "artist.csv"],
                "general": ["general.csv", "é€šç”¨.csv"],
                "quality": ["quality.csv", "è´¨é‡.csv"],
                "meta": ["meta.csv", "å…ƒæ•°æ®.csv", "metadata.csv"],
                "rating": ["rating.csv", "è¯„çº§.csv"]
            }
            
            loaded_files = []
            
            # åŠ è½½æ¯ä¸ªç±»åˆ«çš„æ–‡ä»¶
            for category, possible_names in category_files.items():
                for filename in possible_names:
                    file_path = os.path.join(folder_path, filename)
                    if os.path.exists(file_path):
                        tags = self._load_category_csv_file(file_path)
                        knowledge_base[category].update(tags)
                        loaded_files.append(filename)
                        break  # æ‰¾åˆ°ä¸€ä¸ªå°±è·³å‡º
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é€šç”¨çš„knowledge_base.csvæ–‡ä»¶
            general_csv = os.path.join(folder_path, "knowledge_base.csv")
            if os.path.exists(general_csv):
                general_knowledge = self._load_csv_knowledge_base(general_csv)
                for category, tags in general_knowledge.items():
                    if category in knowledge_base:
                        knowledge_base[category].update(tags)
                loaded_files.append("knowledge_base.csv")
            
            self.safe_log(f"ä»çŸ¥è¯†åº“æ–‡ä»¶å¤¹åŠ è½½äº† {len(loaded_files)} ä¸ªæ–‡ä»¶: {', '.join(loaded_files)}")
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            return {category: tags for category, tags in knowledge_base.items()}
            
        except Exception as e:
            self.safe_log(f"åŠ è½½çŸ¥è¯†åº“æ–‡ä»¶å¤¹å¤±è´¥: {e}", "error")
            return {}
    
    def _load_category_csv_file(self, file_path: str) -> set:
        """åŠ è½½å•ä¸ªç±»åˆ«çš„CSVæ–‡ä»¶"""
        import csv
        tags = set()
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                # è¯»å–ç¬¬ä¸€è¡Œåˆ¤æ–­æ ¼å¼
                first_line = f.readline().strip()
                f.seek(0)
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºCSVæ ¼å¼ï¼ˆåŒ…å«é€—å·å’Œå¯èƒ½çš„æ ‡é¢˜è¡Œï¼‰
                if ',' in first_line and ('tag' in first_line.lower() or 'description' in first_line.lower()):
                    # æœ‰æ ‡é¢˜çš„CSVæ ¼å¼
                    csv_reader = csv.DictReader(f)
                    tag_column = None
                    
                    # æŸ¥æ‰¾æ ‡ç­¾åˆ—ï¼ˆä¼˜å…ˆçº§é¡ºåºï¼‰
                    possible_columns = ['tag', 'tags', 'æ ‡ç­¾', 'name', 'åç§°']
                    for col in possible_columns:
                        if col in csv_reader.fieldnames:
                            tag_column = col
                            break
                    
                    if tag_column:
                        for row in csv_reader:
                            tag = row[tag_column].strip()
                            if tag and not tag.startswith('#') and tag != tag_column:  # é¿å…æŠŠåˆ—åå½“ä½œæ ‡ç­¾
                                tags.add(tag.lower())
                        # self.safe_log(f"ä»CSVæ–‡ä»¶åŠ è½½ {len(tags)} ä¸ªæ ‡ç­¾: {os.path.basename(file_path)}")
                        pass  # é™é»˜å¤„ç†ï¼Œé¿å…é¢‘ç¹æ—¥å¿—
                    else:
                        self.safe_log(f"è­¦å‘Š: åœ¨CSVæ–‡ä»¶ä¸­æœªæ‰¾åˆ°æ ‡ç­¾åˆ— {file_path}", "warning")
                
                elif ',' in first_line:
                    # æ— æ ‡é¢˜çš„CSVæ ¼å¼ï¼Œç¬¬ä¸€åˆ—ä¸ºæ ‡ç­¾
                    f.seek(0)
                    csv_reader = csv.reader(f)
                    for row in csv_reader:
                        if row and len(row) > 0:
                            tag = row[0].strip()
                            if tag and not tag.startswith('#'):
                                tags.add(tag.lower())
                    # self.safe_log(f"ä»æ— æ ‡é¢˜CSVæ–‡ä»¶åŠ è½½ {len(tags)} ä¸ªæ ‡ç­¾: {os.path.basename(file_path)}")
                    pass  # é™é»˜å¤„ç†ï¼Œé¿å…é¢‘ç¹æ—¥å¿—
                
                else:
                    # çº¯æ–‡æœ¬æ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªæ ‡ç­¾
                    f.seek(0)
                    for line in f:
                        tag = line.strip()
                        if tag and not tag.startswith('#') and tag != 'tag':  # é¿å…æŠŠ"tag"æ ‡é¢˜å½“ä½œæ ‡ç­¾
                            tags.add(tag.lower())
                    # self.safe_log(f"ä»æ–‡æœ¬æ–‡ä»¶åŠ è½½ {len(tags)} ä¸ªæ ‡ç­¾: {os.path.basename(file_path)}")
                    pass  # é™é»˜å¤„ç†ï¼Œé¿å…é¢‘ç¹æ—¥å¿—
                            
        except Exception as e:
            self.safe_log(f"åŠ è½½æ–‡ä»¶å¤±è´¥ {file_path}: {e}", "error")
        
        return tags
    
    def _load_csv_knowledge_base(self, file_path: str) -> Dict[str, Dict]:
        """åŠ è½½CSVæ ¼å¼çš„çŸ¥è¯†åº“"""
        import csv
        knowledge_base = {
            "special": set(),
            "characters": set(),
            "copyrights": set(),
            "artists": set(),
            "general": set(),
            "quality": set(),
            "meta": set(),
            "rating": set()
        }
        
        with open(file_path, 'r', encoding='utf-8') as f:
            csv_reader = csv.DictReader(f)
            
            # æ£€æŸ¥å¿…éœ€çš„åˆ—
            if 'tag' not in csv_reader.fieldnames or 'category' not in csv_reader.fieldnames:
                self.safe_log("CSVæ–‡ä»¶å¿…é¡»åŒ…å«'tag'å’Œ'category'åˆ—", "error")
                return {}
            
            for row in csv_reader:
                tag = row['tag'].strip()
                category = row['category'].strip().lower()
                
                if tag and category in knowledge_base:
                    knowledge_base[category].add(tag.lower())
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ˆä¸åŸæ ¼å¼å…¼å®¹ï¼‰
        return {category: tags for category, tags in knowledge_base.items()}
    
    def _load_json_knowledge_base(self, file_path: str) -> Dict[str, Dict]:
        """åŠ è½½JSONæ ¼å¼çš„çŸ¥è¯†åº“"""
        import json
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def get_classification_llm_prompt(self) -> str:
        """è·å–LLMåˆ†ç±»çš„ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Danbooruæ ‡ç­¾åˆ†ç±»å™¨ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹8ä¸ªç±»åˆ«å¯¹æ ‡ç­¾è¿›è¡Œåˆ†ç±»ï¼š

1. **special**: äººæ•°å’ŒåŸºæœ¬ç»„åˆä¿¡æ¯
   - ä¾‹å­: 1girl, 1boy, 2girls, 3boys, solo, multiple girls, multiple boys, duo, group

2. **characters**: å…·ä½“çš„è§’è‰²åç§°ï¼ˆåŠ¨æ¼«ã€æ¸¸æˆã€è™šæ‹Ÿè§’è‰²ç­‰ï¼‰
   - ä¾‹å­: hatsune miku, reimu hakurei, pikachu, naruto uzumaki, artoria pendragon

3. **copyrights**: ç‰ˆæƒä½œå“ã€ç³»åˆ—ã€å“ç‰Œåç§°
   - ä¾‹å­: vocaloid, touhou, pokemon, naruto, fate/grand order, original

4. **artists**: ç”»å¸ˆã€ä½œè€…åç§°
   - ä¾‹å­: wlop, artgerm, by xxx, artist:xxx ç­‰ç”»å¸ˆç›¸å…³æ ‡ç­¾

5. **general**: é€šç”¨æè¿°æ ‡ç­¾ï¼ˆå¤–è§‚ã€æœè£…ã€åŠ¨ä½œã€è¡¨æƒ…ã€åœºæ™¯ç­‰ï¼‰
   - ä¾‹å­: long hair, blue eyes, school uniform, smile, standing, outdoors

6. **quality**: å›¾ç‰‡è´¨é‡å’Œç¾æœ¯è´¨é‡ç›¸å…³
   - ä¾‹å­: masterpiece, best quality, high quality, worst quality, blurry, jpeg artifacts

7. **meta**: æŠ€æœ¯å…ƒæ•°æ®ã€åˆ†è¾¨ç‡ã€æ¥æºç­‰
   - ä¾‹å­: highres, absurdres, official art, scan, pixiv, twitter

8. **rating**: å†…å®¹åˆ†çº§å’Œå®¡æŸ¥ç›¸å…³
   - ä¾‹å­: safe, questionable, explicit, nsfw, sfw, rating:safe

åˆ†ç±»è§„åˆ™ï¼š
- å¦‚æœä¸ç¡®å®šï¼Œä¼˜å…ˆåˆ†ç±»åˆ°general
- ä¿æŒåŸå§‹æ ‡ç­¾æ ¼å¼ï¼Œä¸è¦ä¿®æ”¹
- æ¯ä¸ªæ ‡ç­¾åªèƒ½å±äºä¸€ä¸ªç±»åˆ«
- ç¡®ä¿æ‰€æœ‰è¾“å…¥æ ‡ç­¾éƒ½è¢«åˆ†ç±»

è¯·ä»¥ä¸¥æ ¼çš„JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šï¼š
{
  "special": [],
  "characters": [],
  "copyrights": [],
  "artists": [],
  "general": [],
  "quality": [],
  "meta": [],
  "rating": []
}"""

    def classify_tags_with_llm(self, tags: str, api_url: str, api_key: str, model_name: str, proxy_http: str = "", proxy_https: str = "") -> Dict[str, List[str]]:
        """ä½¿ç”¨LLMè¿›è¡Œæ ‡ç­¾åˆ†ç±»"""
        if not api_key:
            return self.classify_tags(tags, set(), set(), set())
        
        system_prompt = self.get_classification_llm_prompt()
        user_prompt = f"è¯·å¯¹ä»¥ä¸‹æ ‡ç­¾è¿›è¡Œåˆ†ç±»ï¼š{tags}"
        
        try:
            response = self.call_classification_llm_api(api_url, api_key, model_name, system_prompt, user_prompt, proxy_http, proxy_https)
            
            if response.startswith("APIè°ƒç”¨å¤±è´¥"):
                self.safe_log(f"LLMåˆ†ç±»APIè°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°æœ¬åœ°åˆ†ç±»: {response}", "warning")
                return self.classify_tags(tags, set(), set(), set())
            
            # å°è¯•è§£æJSONå“åº”
            import json
            # æ¸…ç†å“åº”å†…å®¹
            clean_response = response.strip()
            
            # æå–JSONéƒ¨åˆ†
            json_start = clean_response.find('{')
            json_end = clean_response.rfind('}') + 1
            
            if json_start != -1 and json_end > json_start:
                json_str = clean_response[json_start:json_end]
                try:
                    classified = json.loads(json_str)
                    
                    # éªŒè¯åˆ†ç±»ç»“æœæ ¼å¼
                    expected_keys = ["special", "characters", "copyrights", "artists", "general", "quality", "meta", "rating"]
                    for key in expected_keys:
                        if key not in classified:
                            classified[key] = []
                        # ç¡®ä¿æ¯ä¸ªå€¼éƒ½æ˜¯åˆ—è¡¨
                        if not isinstance(classified[key], list):
                            classified[key] = []
                    
                    # éªŒè¯åˆ†ç±»ç»“æœä¸ä¸ºç©º
                    total_tags = sum(len(v) for v in classified.values())
                    input_tags = len([tag.strip() for tag in tags.split(',') if tag.strip()])
                    
                    self.safe_log(f"LLMåˆ†ç±»ç»“æœ: è¾“å…¥{input_tags}ä¸ªæ ‡ç­¾ï¼Œåˆ†ç±»äº†{total_tags}ä¸ªæ ‡ç­¾")
                    
                    if total_tags > 0:
                        return classified
                    else:
                        self.safe_log("LLMåˆ†ç±»ç»“æœä¸ºç©ºï¼Œå›é€€åˆ°æœ¬åœ°åˆ†ç±»", "warning")
                        return self.classify_tags(tags, set(), set(), set())
                        
                except json.JSONDecodeError as e:
                    self.safe_log(f"JSONè§£æå¤±è´¥: {e}, å“åº”å†…å®¹: {json_str[:200]}...", "error")
                    return self.classify_tags(tags, set(), set(), set())
            else:
                self.safe_log(f"æ— æ³•ä»å“åº”ä¸­æå–JSONï¼Œå“åº”å†…å®¹: {clean_response[:200]}...", "error")
                return self.classify_tags(tags, set(), set(), set())
                
        except Exception as e:
            self.safe_log(f"LLMåˆ†ç±»å¼‚å¸¸ï¼Œå›é€€åˆ°æœ¬åœ°åˆ†ç±»: {e}", "error")
            return self.classify_tags(tags, set(), set(), set())

    def classify_tags_with_knowledge_base(self, tags: str, knowledge_base: Dict, 
                                        custom_chars: set, custom_artists: set, custom_copyrights: set) -> Dict[str, List[str]]:
        """ä½¿ç”¨çŸ¥è¯†åº“è¿›è¡Œæ ‡ç­¾åˆ†ç±»"""
        tag_list = [tag.strip() for tag in tags.split(',') if tag.strip()]
        
        classified = {
            "special": [],
            "characters": [],
            "copyrights": [],
            "artists": [],
            "general": [],
            "quality": [],
            "meta": [],
            "rating": []
        }
        
        # åˆå¹¶çŸ¥è¯†åº“å’Œå†…ç½®æ•°æ®åº“ï¼ˆå¤–éƒ¨çŸ¥è¯†åº“ä¼˜å…ˆçº§æ›´é«˜ï¼‰
        merged_database = {}
        
        # é¦–å…ˆåŠ è½½å†…ç½®æ•°æ®åº“
        for category, tags in self.tag_database.items():
            merged_database[category] = set(tags) if not isinstance(tags, set) else tags.copy()
        
        # ç„¶ååˆå¹¶å¤–éƒ¨çŸ¥è¯†åº“ï¼Œå¹¶å¤„ç†é‡å¤æ ‡ç­¾ï¼ˆæŒ‰ä¼˜å…ˆçº§é¡ºåºå¤„ç†ï¼‰
        if knowledge_base:
            # æŒ‰ä¼˜å…ˆçº§é¡ºåºå¤„ç†ç±»åˆ«ï¼Œç¡®ä¿é‡è¦ç±»åˆ«çš„æ ‡ç­¾ä¸è¢«è¦†ç›–
            priority_order = ['special', 'quality', 'rating', 'meta', 'characters', 'copyrights', 'artists', 'general']
            
            # æ”¶é›†æ‰€æœ‰å·²åˆ†ç±»çš„æ ‡ç­¾ï¼Œé¿å…é‡å¤
            classified_tags = set()
            
            for category in priority_order:
                if category in knowledge_base:
                    external_tags = knowledge_base[category]
                    
                    if category not in merged_database:
                        merged_database[category] = set()
                    
                    # ç¡®ä¿æ˜¯setç±»å‹
                    if not isinstance(merged_database[category], set):
                        merged_database[category] = set(merged_database[category])
                    if not isinstance(external_tags, set):
                        external_tags = set(external_tags)
                    
                    # åªæ·»åŠ å°šæœªè¢«åˆ†ç±»çš„æ ‡ç­¾
                    new_tags = external_tags - classified_tags
                    merged_database[category].update(new_tags)
                    classified_tags.update(new_tags)
            
            # å¤„ç†å…¶ä»–æœªæŒ‰ä¼˜å…ˆçº§å¤„ç†çš„ç±»åˆ«
            for category, external_tags in knowledge_base.items():
                if category not in priority_order:
                    if category not in merged_database:
                        merged_database[category] = set()
                    
                    if not isinstance(external_tags, set):
                        external_tags = set(external_tags)
                    
                    new_tags = external_tags - classified_tags
                    merged_database[category].update(new_tags)
                    classified_tags.update(new_tags)
        
        # ç¡®ä¿æ‰€æœ‰æœªåˆ†ç±»çš„æ ‡ç­¾éƒ½æœ‰é»˜è®¤ç±»åˆ«
        for category in ["special", "characters", "copyrights", "artists", "general", "quality", "meta", "rating"]:
            if category not in merged_database:
                merged_database[category] = set()
        
        for tag in tag_list:
            category = self.classify_single_tag_with_knowledge(tag, merged_database, custom_chars, custom_artists, custom_copyrights)
            classified[category].append(tag)
        
        return classified

    def classify_single_tag_with_knowledge(self, tag: str, knowledge_base: Dict, 
                                         custom_chars: set, custom_artists: set, custom_copyrights: set) -> str:
        """ä½¿ç”¨çŸ¥è¯†åº“åˆ†ç±»å•ä¸ªæ ‡ç­¾ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        tag_lower = tag.lower().strip()
        
        # æŒ‰ä¼˜å…ˆçº§é¡ºåºæ£€æŸ¥ï¼Œé¿å…ä¸å¿…è¦çš„å¾ªç¯
        
        # 1. æ£€æŸ¥specialç±»åˆ«ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œé€šå¸¸æ˜¯æ•°é‡æ ‡ç­¾ï¼‰
        if 'special' in knowledge_base and tag_lower in knowledge_base['special']:
            return "special"
        
        # 2. æ£€æŸ¥è‡ªå®šä¹‰æ ‡ç­¾ï¼ˆç”¨æˆ·æŒ‡å®šçš„ä¼˜å…ˆçº§é«˜ï¼‰
        if tag in custom_chars:
            return "characters"
        if tag in custom_artists:
            return "artists"
        if tag in custom_copyrights:
            return "copyrights"
        
        # 3. æ£€æŸ¥qualityå’Œratingï¼ˆè¿™äº›å¾ˆé‡è¦ä¸”æ•°é‡å°‘ï¼‰
        for priority_category in ['quality', 'rating']:
            if priority_category in knowledge_base and tag_lower in knowledge_base[priority_category]:
                return priority_category
        
        # 4. æ£€æŸ¥éè§’è‰²æ¨¡å¼ï¼Œé˜²æ­¢å¸¸è§æ ‡ç­¾è¢«è¯¯åˆ†ç±»ä¸ºè§’è‰²
        for pattern in self.non_character_patterns:
            if pattern.match(tag_lower):
                return "general"
        
        # 5. æ£€æŸ¥generalç±»åˆ«ï¼ˆæœ€å¤§çš„ç±»åˆ«ï¼Œä½†åœ¨æ¨¡å¼åŒ¹é…ä¹‹å‰æ£€æŸ¥ï¼‰
        if 'general' in knowledge_base and tag_lower in knowledge_base['general']:
            return "general"
        
        # 6. æ£€æŸ¥characterså’Œcopyrightsï¼ˆåœ¨generalä¹‹åï¼Œé¿å…è¯¯åˆ†ç±»ï¼‰
        if 'characters' in knowledge_base and tag_lower in knowledge_base['characters']:
            return "characters"
        
        if 'copyrights' in knowledge_base and tag_lower in knowledge_base['copyrights']:
            return "copyrights"
        
        # 7. æ£€æŸ¥ç‰ˆæƒå…³é”®è¯
        if tag_lower in self.copyright_keywords:
            return "copyrights"
        
        # 8. æ£€æŸ¥artistså’Œmeta
        if 'artists' in knowledge_base and tag_lower in knowledge_base['artists']:
            return "artists"
        
        if 'meta' in knowledge_base and tag_lower in knowledge_base['meta']:
            return "meta"
        
        # 9. åŸºäºæ¨¡å¼åŒ¹é…ï¼ˆæœ€åçš„fallbackï¼‰
        for pattern in self.character_patterns:
            if pattern.match(tag):
                return "characters"
        
        for pattern in self.artist_patterns:
            if pattern.match(tag):
                return "artists"
        
        # 10. é»˜è®¤è¿”å›general
        return "general"

    def replace_numbers_with_english(self, text: str) -> str:
        """å°†æ•°å­—æ›¿æ¢ä¸ºè‹±æ–‡"""
        number_map = {
            '20': 'twenty', '19': 'nineteen', '18': 'eighteen', '17': 'seventeen',
            '16': 'sixteen', '15': 'fifteen', '14': 'fourteen', '13': 'thirteen',
            '12': 'twelve', '11': 'eleven', '10': 'ten', '9': 'nine', '8': 'eight',
            '7': 'seven', '6': 'six', '5': 'five', '4': 'four', '3': 'three',
            '2': 'two', '1': 'one', '0': 'zero'
        }
        
        # ä»å¤§åˆ°å°æ›¿æ¢æ•°å­—ï¼Œé¿å…éƒ¨åˆ†åŒ¹é…é—®é¢˜
        for num, word in number_map.items():
            # ä½¿ç”¨å•è¯è¾¹ç•Œç¡®ä¿å®Œæ•´åŒ¹é…
            text = re.sub(rf'\b{num}\b', word, text)
        
        return text

    def get_tag_conversion_prompt(self) -> str:
        """è·å–tagè½¬æ¢çš„LLMé¢„è®¾"""
        return """å°†danbooru tagæ ‡ç­¾è½¬åŒ–æˆè‡ªç„¶è¯­è¨€ï¼Œä½ å¯ä»¥å°†è¿™äº›æ ‡ç­¾ä½œä¸ºå‚è€ƒï¼Œä½†ä¸è¦å®Œå…¨ä¾èµ–å®ƒä»¬ï¼Œå› ä¸ºå¯èƒ½å­˜åœ¨é”™è¯¯çš„æ ‡ç­¾ã€‚ä¼˜å…ˆä½¿ç”¨ä½ è‡ªå·±çš„è§‚å¯Ÿï¼Œå¹¶ä½¿ç”¨æ›´åˆé€‚çš„åŒä¹‰è¯è¿›è¡Œæè¿°ã€‚

æ³¨æ„äº‹é¡¹ï¼š
- ç¡®ä¿åœºæ™¯æè¿°çš„å‡†ç¡®æ€§ã€‚
- å¦‚æœåœºæ™¯ä¸ç¬¦åˆä¸Šè¿°è§„åˆ™æˆ–æ— æ³•åˆ†æï¼Œè¯·å‹¿æè¿°ã€‚ä¿æŒæè¿°çš„å‡†ç¡®æ€§ã€‚
- ä½¿ç”¨æ¸…æ™°ç®€æ´çš„è¯­è¨€è¿›è¡Œæè¿°ã€‚é¿å…ä½¿ç”¨å¤æ‚æˆ–éš¾ä»¥ç†è§£çš„è¯­è¨€ã€‚
- æè¿°æ—¶å°½é‡å®¢è§‚ã€‚é¿å…ä½¿ç”¨é«˜åº¦ä¸»è§‚çš„è¯­è¨€ã€‚
- å¦‚æœåœºæ™¯åŒ…å«NSFWæˆ–æ•æ„Ÿå†…å®¹ï¼Œè¯·å‹¿å›é¿ã€‚ç›´æ¥æè¿°éœ²éª¨å†…å®¹ã€‚
- å¦‚æœåœºæ™¯åŒ…å«æš´åŠ›ã€è¡€è…¥ã€ææ€–ã€æ¶å¿ƒæˆ–å…¶ä»–æ•æ„Ÿå†…å®¹ï¼Œè¯·å‹¿å›é¿ã€‚ç›´æ¥æè¿°ã€‚
- ä½¿ç”¨**è‹±æ–‡**è¿›è¡Œæè¿°ã€‚
- æƒ³è±¡ä½ æ˜¯ä¸€åç”¨æˆ·è¯•å›¾æç»˜è¿™ä¸ªåœºæ™¯ã€‚è‡ªç„¶åœ°ç»“åˆå†…å®¹ï¼Œé¿å…ç»“æ„åŒ–çš„æè¿°ã€‚
- åªè¿”å›æè¿°ã€‚ä¸è¦åŒ…å«é¢å¤–å†…å®¹æˆ–åˆ†æã€‚
- ä½ çš„ä»»åŠ¡æ˜¯æè¿°å›¾åƒä¸­çš„æ¯ä¸ªæ–¹é¢ã€å¯¹è±¡å’Œäº’åŠ¨ï¼Œä½¿å¾—ç›²äººåœ¨å¬åˆ°æè¿°æ—¶èƒ½å¤Ÿåœ¨è„‘æµ·ä¸­å®Œç¾æ•æ‰åˆ°å›¾åƒã€‚"""

    def get_theme_enhancement_prompt(self) -> str:
        """è·å–ä¸»é¢˜å¢å¼ºçš„LLMç³»ç»Ÿæç¤ºè¯ï¼ˆåŸºäºæ–°çš„luminaé£æ ¼ï¼‰"""
        return """ç°åœ¨æˆ‘éœ€è¦ä¸€ä¸ªæç¤ºè¯åŠ©æ‰‹ï¼Œæ¥å¸®æˆ‘ç»™å†™æç¤ºè¯ï¼š
ä½ æ˜¯ä¸€ä¸ªéå¸¸æ“…é•¿ç”¨luminaæ¨¡å‹åˆ›ä½œAIç»˜ç”»çš„è‰ºæœ¯å®¶ï¼Œä¼šå†™è´¨é‡å¾ˆé«˜çš„luminaæç¤ºè¯ã€‚è€Œæˆ‘æƒ³è¦ä½¿ç”¨aiè¿›è¡Œåˆ›ä½œï¼Œæ¥ä¸‹æ¥æˆ‘å°†ç»™ä½ ä¸€äº›å…ƒç´ ï¼Œä½ éœ€è¦å€ŸåŠ©è¿™äº›å…ƒç´ å¸®åŠ©æˆ‘å®Œå–„è¿™ä¸ªæç¤ºè¯ï¼Œä½ è¦å°½å¯èƒ½è¯¦ç»†åœ°å¸®æˆ‘æ’°å†™ã€‚
ä½ åº”éµå¾ªä»¥ä¸‹çš„æ€è€ƒè¿‡ç¨‹ã€ä¼˜è´¨å‚è€ƒæç¤ºè¯ï¼Œæˆ‘å°†å‘Šè¯‰ä½ éœ€è¦å›å¤ç»™æˆ‘çš„å†…å®¹ã€‚
æ€è€ƒè¿‡ç¨‹ï¼š
1.æˆ‘ä¼šç»™ä½ æˆ‘éœ€è¦çš„å…ƒç´ ï¼Œä¾‹å¦‚ç¥æ€ã€åŠ¨ä½œã€æœé¥°ã€è‚¢ä½“ã€ç”šè‡³è¯¦ç»†ä¸€ç‚¹å¤´å‘é¢œè‰²ä¹Ÿå¯èƒ½ï¼Œç„¶åä½ å¸®æˆ‘æŒ‰ç…§ä¸€å®šçš„æ ¼å¼æŠŠè¿™äº›ä¸œè¥¿ä¸²è”èµ·æ¥å˜æˆä¸€ä¸ªå®Œæ•´çš„æç¤ºè¯ã€‚
ä½ çš„æç¤ºè¯éœ€è¦æè¿°çš„å†…å®¹æœ‰:ç”»é¢æ‹æ‘„çš„é•œå¤´æ˜¯è¿‘æ™¯ã€ä¸­æ™¯è¿˜æ˜¯è¿œæ™¯ï¼Œä¸»äººç‰©æ‹æ‘„çš„æ˜¯å…¨èº«ã€åŠèº«è¿˜æ˜¯å¤§å¤´ï¼Œä¸»äººç‰©çš„æ€§åˆ«æ˜¯ç”·è¿˜æ˜¯å¥³ã€å¹´é¾„æ˜¯å°å­©è¿˜æ˜¯é’å¹´äººã€ç©¿ç€æè¿°ç»†è‡´ä¸€äº›ï¼Œå¯¹äºå¤´å‘çœ¼ç›è¡£æœç­‰ç­‰é¢œè‰²çš„æè¿°è¦æ±‚æ›´ç²¾å‡†ï¼Œä¾‹å¦‚æ˜¯æ·±è“è¿˜æ˜¯æµ…è“ã€äººç‰©æœå‘å·¦è¿˜æ˜¯å³ï¼Œè§’åº¦æœ‰å¤šå¤§ï¼Œè¿˜æœ‰ç‰¹å¾ä»¥åŠåŠ¨ä½œç­‰ç­‰ã€‚
2.æˆ‘ç»™çš„å…ƒç´ å¯èƒ½åªåŒ…å«ä¸Šè¿°æç¤ºè¯ä¸­çš„ä¸€éƒ¨åˆ†ï¼Œå‰©ä¸‹çš„ä½ è¦è‡ªå·±è„‘è¡¥ã€‚
3.å…è®¸ä½ æ‹¥æœ‰æƒ³è±¡åŠ›å’Œè‡ªç”±å‘æŒ¥ç©ºé—´ï¼Œå¯¹å¯ä»¥å…³è”åˆ°çš„äººç‰©ã€ç‰©å“ã€åœºæ™¯è¿›è¡Œä¼˜åŒ–ï¼Œä»¥è®©ç”»é¢ç»†èŠ‚éå¸¸ä¸°å¯Œã€å……æ»¡æé«˜çš„ç¾æ„Ÿï¼Œè¶Šè¯¦ç»†è¶Šå¥½ã€‚
4.å°è¯•æ€è€ƒå‡ºèƒ½ä½¿å¾—aiæ›´å¥½ä½œç”»ã€æ›´èƒ½ç†è§£çš„æ–¹æ¡ˆã€‚
ä½ éœ€è¦å›å¤æˆ‘çš„å†…å®¹ï¼š
åªè¾“å‡ºå®Œæ•´çš„è‹±æ–‡Captionæç¤ºè¯ï¼Œä¸éœ€è¦å…¶ä»–ä»»ä½•å†…å®¹ã€‚
æ³¨æ„ï¼šåªè¿”å›è‡ªç„¶è¯­è¨€æè¿°ï¼Œä¸è¦åŒ…å«æ ‡ç­¾æ ¼å¼ã€‚"""

    def call_openai_api(self, api_key: str, model: str, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨OpenAI API"""
        try:
            import openai
            client = openai.OpenAI(api_key=api_key)
            
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=1000,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"OpenAI APIè°ƒç”¨å¤±è´¥: {str(e)}"

    def call_claude_api(self, api_key: str, model: str, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨Claude API"""
        try:
            import anthropic
            client = anthropic.Anthropic(api_key=api_key)
            
            response = client.messages.create(
                model=model,
                max_tokens=1000,
                temperature=0.7,
                system=system_prompt,
                messages=[
                    {"role": "user", "content": user_prompt}
                ]
            )
            
            return response.content[0].text.strip()
            
        except Exception as e:
            return f"Claude APIè°ƒç”¨å¤±è´¥: {str(e)}"



    def call_deepseek_api(self, api_key: str, model: str, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨DeepSeek APIï¼Œæ”¯æŒä»£ç†"""
        try:
            # è·å–ç³»ç»Ÿä»£ç†è®¾ç½®
            proxies = get_system_proxy()
            
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "stream": False,
                "max_tokens": 1000,
                "temperature": 0.7
            }
            
            response = requests.post("https://api.deepseek.com/chat/completions", 
                                   headers=headers, json=data, proxies=proxies, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
            
        except Exception as e:
            return f"DeepSeek APIè°ƒç”¨å¤±è´¥: {str(e)}"

    def call_custom_api(self, api_url: str, api_key: str, model: str, system_prompt: str, user_prompt: str) -> str:
        """è°ƒç”¨è‡ªå®šä¹‰APIï¼Œæ”¯æŒä»£ç†"""
        try:
            # æ¸…ç†å’ŒéªŒè¯API URL
            clean_api_url = self.clean_and_validate_url(api_url)
            
            # è·å–ç³»ç»Ÿä»£ç†è®¾ç½®
            proxies = get_system_proxy()
            
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "stream": False,
                "max_tokens": 1000,
                "temperature": 0.7
            }
            
            response = requests.post(clean_api_url, headers=headers, json=data, 
                                   proxies=proxies, timeout=self.DEFAULT_TIMEOUT)
            response.raise_for_status()
            
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
            
        except Exception as e:
            return f"è‡ªå®šä¹‰APIè°ƒç”¨å¤±è´¥: {str(e)}"

    def call_llm_api(self, ai_model: str, api_key: str, model_name: str, system_prompt: str, user_prompt: str, custom_api_url: str = "") -> str:
        """ç»Ÿä¸€çš„LLM APIè°ƒç”¨æ¥å£"""
        if not api_key:
            return "APIå¯†é’¥æœªè®¾ç½®"
        
        if ai_model == "openai":
            return self.call_openai_api(api_key, model_name, system_prompt, user_prompt)
        elif ai_model == "claude":
            return self.call_claude_api(api_key, model_name, system_prompt, user_prompt)
        elif ai_model == "gemini":
            return self.call_gemini_api(api_key, model_name, system_prompt, user_prompt, custom_api_url)
        elif ai_model == "deepseek":
            return self.call_deepseek_api(api_key, model_name, system_prompt, user_prompt)
        elif ai_model == "custom":
            if not custom_api_url:
                return "è‡ªå®šä¹‰æ¨¡å¼éœ€è¦æä¾›API URL"
            return self.call_custom_api(custom_api_url, api_key, model_name, system_prompt, user_prompt)
        else:
            return f"ä¸æ”¯æŒçš„AIæ¨¡å‹: {ai_model}"

    def enhance_with_llm(self, tags: str, drawing_theme: str, api_url: str, api_key: str, model_name: str, proxy_http: str = "", proxy_https: str = "") -> str:
        """ä½¿ç”¨LLMå¢å¼ºæç¤ºè¯ï¼Œæ ¹æ®è¾“å…¥æƒ…å†µé€‰æ‹©ä¸åŒç­–ç•¥"""
        if not api_key:
            return ""
        
        has_tags = bool(tags.strip())
        has_theme = bool(drawing_theme.strip())
        
        if has_tags and has_theme:
            # åŒæ—¶æœ‰tagå’Œç»˜å›¾ä¸»é¢˜ï¼šä½¿ç”¨æ–°çš„ä¸»é¢˜å¢å¼ºç­–ç•¥
            system_prompt = self.get_theme_enhancement_prompt()
            user_prompt = f"è¯·ä»¥ä»¥ä¸‹å†…å®¹ï¼ˆç»˜å›¾ä¸»é¢˜æç¤ºè¯ï¼‰ä¸»é¢˜ç»“åˆtagæç¤ºè¯ç”Ÿæˆå†…å®¹ï¼š\nä¸»é¢˜ï¼š{drawing_theme}\nTagæç¤ºè¯ï¼š{tags}"
            
        elif has_tags and not has_theme:
            # åªæœ‰tagï¼šè½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€
            system_prompt = self.get_tag_conversion_prompt()
            user_prompt = f"è¯·å°†ä»¥ä¸‹danbooruæ ‡ç­¾è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€æè¿°ï¼š{tags}"
            
        elif not has_tags and has_theme:
            # åªæœ‰ç»˜å›¾ä¸»é¢˜ï¼šä½¿ç”¨ä¸»é¢˜å¢å¼º
            system_prompt = self.get_theme_enhancement_prompt()
            user_prompt = drawing_theme
            
        else:
            # éƒ½æ²¡æœ‰è¾“å…¥
            return ""
        
        return self.call_simple_llm_api(api_url, api_key, model_name, system_prompt, user_prompt, proxy_http, proxy_https)



    def call_simple_llm_api(self, api_url: str, api_key: str, model: str, system_prompt: str, user_prompt: str, proxy_http: str = "", proxy_https: str = "") -> str:
        """ç®€åŒ–çš„LLM APIè°ƒç”¨ï¼Œæ”¯æŒGeminiè‡ªåŠ¨æ ¼å¼è½¬æ¢å’Œä»£ç†"""
        try:
            # æ¸…ç†å’ŒéªŒè¯API URL
            clean_api_url = self.clean_and_validate_url(api_url)
            
            # è·å–ä»£ç†è®¾ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨è®¾ç½®ï¼‰
            proxies = get_system_proxy(proxy_http, proxy_https)
            if proxies:
                self.safe_log(f"ğŸŒ ä½¿ç”¨ä»£ç†è®¾ç½®: {proxies}")
            
            # æ£€æµ‹Gemini APIå¹¶è‡ªåŠ¨è½¬æ¢æ ¼å¼
            if "generativelanguage.googleapis.com" in clean_api_url or "gemini" in model.lower():
                return self._call_gemini_api(api_key, model, system_prompt, user_prompt, proxies)
            
            # æ ‡å‡†çš„OpenAIå…¼å®¹APIè°ƒç”¨
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "stream": False,
                "max_tokens": 1000,
                "temperature": 0.7
            }
            
            response = requests.post(clean_api_url, headers=headers, json=data, 
                                   proxies=proxies, timeout=self.DEFAULT_TIMEOUT)
            response.raise_for_status()
            
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
            
        except requests.exceptions.Timeout:
            return "APIè°ƒç”¨è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
        except Exception as e:
            return f"APIè°ƒç”¨å¤±è´¥: {str(e)}"

    def _call_gemini_api(self, api_key: str, model: str, system_prompt: str, user_prompt: str, proxies=None) -> str:
        """ç®€åŒ–çš„Gemini APIè°ƒç”¨ï¼Œå‚è€ƒ gemini_nodes.py çš„æ­£ç¡®å®ç°"""
        try:
            # éªŒè¯å’Œä¿®æ­£æ¨¡å‹åç§°
            corrected_model = self._validate_gemini_model_name(model)
            
            # ä½¿ç”¨å’Œ gemini_nodes.py ç›¸åŒçš„è°ƒç”¨æ–¹å¼
            import httpx
            
            # è½¬æ¢ä»£ç†æ ¼å¼ä¸º httpx å…¼å®¹æ ¼å¼
            httpx_proxies = None
            if proxies:
                httpx_proxies = {}
                if 'http' in proxies and proxies['http']:
                    httpx_proxies['http://'] = proxies['http']
                if 'https' in proxies and proxies['https']:
                    httpx_proxies['https://'] = proxies['https']
                self.safe_log(f"ğŸŒ ä½¿ç”¨ä»£ç† (httpxæ ¼å¼): {httpx_proxies}")
            else:
                self.safe_log("ğŸŒ æœªä½¿ç”¨ä»£ç†")
            
            # åˆ›å»º httpx å®¢æˆ·ç«¯
            client = httpx.Client(
                base_url="https://generativelanguage.googleapis.com",
                params={'key': api_key},
                proxies=httpx_proxies,
                timeout=self.DEFAULT_TIMEOUT
            )
            
            try:
                # æ„å»ºè¯·æ±‚ä½“
                combined_prompt = f"{system_prompt}\n\n{user_prompt}"
                
                body = {
                    "contents": [{
                        "parts": [{"text": combined_prompt}]
                    }],
                    "generationConfig": {
                        "maxOutputTokens": 4000,
                        "temperature": 0.7
                    }
                }
                
                # ä½¿ç”¨ç›¸å¯¹ç«¯ç‚¹è·¯å¾„
                endpoint = f"/v1beta/models/{corrected_model}:generateContent"
                
                response = client.post(endpoint, json=body)
                
                # å¢å¼ºé”™è¯¯å¤„ç†
                if response.status_code == 400:
                    error_detail = ""
                    try:
                        error_json = response.json()
                        error_detail = error_json.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                    except:
                        error_detail = f"HTTP 400 - è¯·æ£€æŸ¥æ¨¡å‹åç§°å’Œ API å¯†é’¥"
                    return f"Gemini APIè¯·æ±‚é”™è¯¯: {error_detail}"
                
                response.raise_for_status()
                
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    candidate = result['candidates'][0]
                    if 'content' in candidate and 'parts' in candidate['content']:
                        parts = candidate['content']['parts']
                        if len(parts) > 0 and 'text' in parts[0]:
                            return parts[0]['text'].strip()
                
                return "Gemini APIå“åº”æ ¼å¼å¼‚å¸¸"
                
            finally:
                client.close()
            
        except ImportError:
            # å¦‚æœ httpx ä¸å¯ç”¨ï¼Œå›é€€åˆ° requests æ–¹æ³•
            return self._call_gemini_api_requests_fallback(api_key, model, system_prompt, user_prompt, proxies)
        except Exception as e:
            return f"Gemini APIè°ƒç”¨å¤±è´¥: {str(e)}"
    
    def _call_gemini_api_requests_fallback(self, api_key: str, model: str, system_prompt: str, user_prompt: str, proxies=None) -> str:
        """ä½¿ç”¨ requests çš„ Gemini API è°ƒç”¨å¤‡ç”¨æ–¹æ³•"""
        try:
            corrected_model = self._validate_gemini_model_name(model)
            
            # ä¿®æ­£ï¼šAPI å¯†é’¥åº”è¯¥é€šè¿‡ URL å‚æ•°ä¼ é€’ï¼Œè€Œä¸æ˜¯ header
            api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{corrected_model}:generateContent?key={api_key}"
            
            headers = {
                "Content-Type": "application/json"
            }
            
            combined_prompt = f"{system_prompt}\n\n{user_prompt}"
            
            data = {
                "contents": [{
                    "parts": [{"text": combined_prompt}]
                }],
                "generationConfig": {
                    "maxOutputTokens": 4000,
                    "temperature": 0.7
                }
            }
            
            response = requests.post(api_url, headers=headers, json=data, 
                                   proxies=proxies, timeout=self.DEFAULT_TIMEOUT)
            
            # å¢å¼ºé”™è¯¯å¤„ç†
            if response.status_code == 400:
                error_detail = ""
                try:
                    error_json = response.json()
                    error_detail = error_json.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                except:
                    error_detail = f"HTTP 400 - è¯·æ£€æŸ¥æ¨¡å‹åç§°å’Œ API å¯†é’¥"
                return f"Gemini APIè¯·æ±‚é”™è¯¯: {error_detail}"
            
            response.raise_for_status()
            
            result = response.json()
            if 'candidates' in result and len(result['candidates']) > 0:
                candidate = result['candidates'][0]
                if 'content' in candidate and 'parts' in candidate['content']:
                    parts = candidate['content']['parts']
                    if len(parts) > 0 and 'text' in parts[0]:
                        return parts[0]['text'].strip()
            
            return "Gemini APIå“åº”æ ¼å¼å¼‚å¸¸"
            
        except requests.exceptions.Timeout:
            return "Gemini APIè°ƒç”¨è¶…æ—¶"
        except Exception as e:
            return f"Gemini APIè°ƒç”¨å¤±è´¥: {str(e)}"
    
    def _validate_gemini_model_name(self, model: str) -> str:
        """éªŒè¯å’Œä¿®æ­£ Gemini æ¨¡å‹åç§°"""
        # å¸¸è§çš„æ­£ç¡®æ¨¡å‹åç§°æ˜ å°„ï¼ˆæ›´æ–°æ”¯æŒ gemini-2.5-flashï¼‰
        model_mapping = {
            "gemini-2.0-flash": "gemini-2.0-flash-001", 
            "gemini-flash": "gemini-2.0-flash-001",
            "gemini-1.5-pro": "gemini-1.5-pro",
            "gemini-pro": "gemini-1.5-pro",
            "gemini-1.5-flash": "gemini-1.5-flash",
            # gemini-2.5-flash åº”è¯¥æ˜¯æœ‰æ•ˆçš„ï¼Œä¸éœ€è¦æ˜ å°„
        }
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿®æ­£
        if model in model_mapping:
            corrected = model_mapping[model]
            self.safe_log(f"ğŸ”§ Geminiæ¨¡å‹åç§°ä¿®æ­£: {model} -> {corrected}")
            return corrected
        
        # å¦‚æœæ¨¡å‹åå·²ç»æ­£ç¡®æˆ–æœªçŸ¥ï¼Œç›´æ¥è¿”å›
        return model

    def call_classification_llm_api(self, api_url: str, api_key: str, model: str, system_prompt: str, user_prompt: str, proxy_http: str = "", proxy_https: str = "") -> str:
        """ä¸“é—¨ç”¨äºåˆ†ç±»çš„LLM APIè°ƒç”¨ï¼Œä½¿ç”¨æ›´ä½çš„temperatureä»¥è·å¾—æ›´ç¨³å®šçš„ç»“æœ"""
        try:
            # æ¸…ç†å’ŒéªŒè¯API URL
            clean_api_url = self.clean_and_validate_url(api_url)
            
            # è·å–ä»£ç†è®¾ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨è®¾ç½®ï¼‰
            proxies = get_system_proxy(proxy_http, proxy_https)
            
            # æ£€æµ‹æ˜¯å¦ä¸ºGemini API
            if "generativelanguage.googleapis.com" in clean_api_url or "gemini" in model.lower():
                return self._call_gemini_classification(api_key, model, system_prompt, user_prompt, proxies)
            
            # æ ‡å‡†çš„OpenAIå…¼å®¹APIè°ƒç”¨
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "stream": False,
                "max_tokens": 2000,  # åˆ†ç±»éœ€è¦æ›´å¤štoken
                "temperature": 0.1   # åˆ†ç±»éœ€è¦æ›´ç¡®å®šæ€§çš„è¾“å‡º
            }
            
            response = requests.post(clean_api_url, headers=headers, json=data, 
                                   proxies=proxies, timeout=self.DEFAULT_TIMEOUT)
            response.raise_for_status()
            
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
            
        except requests.exceptions.Timeout:
            return "åˆ†ç±»APIè°ƒç”¨è¶…æ—¶"
        except Exception as e:
            return f"APIè°ƒç”¨å¤±è´¥: {str(e)}"
    
    def _call_gemini_classification(self, api_key: str, model: str, system_prompt: str, user_prompt: str, proxies=None) -> str:
        """ç®€åŒ–çš„Geminiåˆ†ç±»APIè°ƒç”¨ï¼Œå‚è€ƒ gemini_nodes.py çš„æ­£ç¡®å®ç°"""
        try:
            # éªŒè¯å’Œä¿®æ­£æ¨¡å‹åç§°
            corrected_model = self._validate_gemini_model_name(model)
            
            try:
                # å°è¯•ä½¿ç”¨ httpxï¼ˆæ¨èæ–¹å¼ï¼‰
                import httpx
                
                # è½¬æ¢ä»£ç†æ ¼å¼ä¸º httpx å…¼å®¹æ ¼å¼
                httpx_proxies = None
                if proxies:
                    httpx_proxies = {}
                    if 'http' in proxies and proxies['http']:
                        httpx_proxies['http://'] = proxies['http']
                    if 'https' in proxies and proxies['https']:
                        httpx_proxies['https://'] = proxies['https']
                    self.safe_log(f"ğŸŒ åˆ†ç±»APIä½¿ç”¨ä»£ç† (httpxæ ¼å¼): {httpx_proxies}")
                else:
                    self.safe_log("ğŸŒ åˆ†ç±»APIæœªä½¿ç”¨ä»£ç†")
                
                client = httpx.Client(
                    base_url="https://generativelanguage.googleapis.com",
                    params={'key': api_key},
                    proxies=httpx_proxies,
                    timeout=self.DEFAULT_TIMEOUT
                )
                
                try:
                    combined_prompt = f"{system_prompt}\n\n{user_prompt}"
                    
                    body = {
                        "contents": [{
                            "parts": [{"text": combined_prompt}]
                        }],
                        "generationConfig": {
                            "maxOutputTokens": 2000,
                            "temperature": 0.1
                        }
                    }
                    
                    endpoint = f"/v1beta/models/{corrected_model}:generateContent"
                    response = client.post(endpoint, json=body)
                    
                    if response.status_code == 400:
                        error_detail = ""
                        try:
                            error_json = response.json()
                            error_detail = error_json.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                        except:
                            error_detail = f"HTTP 400 - è¯·æ£€æŸ¥æ¨¡å‹åç§°å’Œ API å¯†é’¥"
                        return f"Geminiåˆ†ç±»APIè¯·æ±‚é”™è¯¯: {error_detail}"
                    
                    response.raise_for_status()
                    
                    result = response.json()
                    if 'candidates' in result and len(result['candidates']) > 0:
                        candidate = result['candidates'][0]
                        if 'content' in candidate and 'parts' in candidate['content']:
                            parts = candidate['content']['parts']
                            if len(parts) > 0 and 'text' in parts[0]:
                                return parts[0]['text'].strip()
                    
                    return "Geminiåˆ†ç±»APIå“åº”æ ¼å¼å¼‚å¸¸"
                    
                finally:
                    client.close()
                    
            except ImportError:
                # å›é€€åˆ° requests æ–¹æ³•
                corrected_model = self._validate_gemini_model_name(model)
                
                # ä¿®æ­£ï¼šAPI å¯†é’¥é€šè¿‡ URL å‚æ•°ä¼ é€’
                api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{corrected_model}:generateContent?key={api_key}"
                
                headers = {
                    "Content-Type": "application/json"
                }
                
                combined_prompt = f"{system_prompt}\n\n{user_prompt}"
                
                data = {
                    "contents": [{
                        "parts": [{"text": combined_prompt}]
                    }],
                    "generationConfig": {
                        "maxOutputTokens": 2000,
                        "temperature": 0.1
                    }
                }
                
                response = requests.post(api_url, headers=headers, json=data, 
                                       proxies=proxies, timeout=self.DEFAULT_TIMEOUT)
                
                if response.status_code == 400:
                    error_detail = ""
                    try:
                        error_json = response.json()
                        error_detail = error_json.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                    except:
                        error_detail = f"HTTP 400 - è¯·æ£€æŸ¥æ¨¡å‹åç§°å’Œ API å¯†é’¥"
                    return f"Geminiåˆ†ç±»APIè¯·æ±‚é”™è¯¯: {error_detail}"
                
                response.raise_for_status()
                
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    candidate = result['candidates'][0]
                    if 'content' in candidate and 'parts' in candidate['content']:
                        parts = candidate['content']['parts']
                        if len(parts) > 0 and 'text' in parts[0]:
                            return parts[0]['text'].strip()
                
                return "Geminiåˆ†ç±»APIå“åº”æ ¼å¼å¼‚å¸¸"
            
        except Exception as e:
            return f"Geminiåˆ†ç±»APIè°ƒç”¨å¤±è´¥: {str(e)}"

    def apply_text_formatting(self, text: str) -> str:
        """åº”ç”¨æ–‡æœ¬æ ¼å¼åŒ–å¤„ç†"""
        if not text:
            return text
        
        # å»é™¤ä¸‹åˆ’çº¿ï¼Œæ›¿æ¢ä¸ºç©ºæ ¼
        text = re.sub(r'_', ' ', text)
        
        # è½¬ä¹‰æ‹¬å·ï¼ˆé™¤äº†æƒé‡æ‹¬å·ï¼‰
        # ä¿æŠ¤æƒé‡æ‹¬å·æ ¼å¼ (tag:weight)
        protected_weights = []
        weight_pattern = r'\([^:()]+:\d*\.?\d+\)'
        
        # æå–å¹¶ä¿æŠ¤æƒé‡æ‹¬å·
        matches = re.finditer(weight_pattern, text)
        for i, match in enumerate(matches):
            placeholder = f"__WEIGHT_{i}__"
            protected_weights.append((placeholder, match.group()))
            text = text.replace(match.group(), placeholder)
        
        # è½¬ä¹‰æ™®é€šæ‹¬å·
        text = re.sub(r'\((?![^:()]+:\d*\.?\d+\))', r'\\(', text)
        text = re.sub(r'(?<!\d)\)', r'\\)', text)
        
        # æ¢å¤æƒé‡æ‹¬å·
        for placeholder, original in protected_weights:
            text = text.replace(placeholder, original)
        
        return text

    def apply_symbol_enhancement(self, classified_tags: Dict[str, List[str]], enable_enhancement: bool) -> Dict[str, List[str]]:
        """åº”ç”¨ç¬¦å·å¼ºåŒ–åˆ°æŒ‡å®šç±»åˆ«çš„æ ‡ç­¾"""
        if not enable_enhancement:
            return classified_tags
        
        result = classified_tags.copy()
        
        # åº”ç”¨è§’è‰²ç¬¦å·å¼ºåŒ–ï¼šå‰ç¼€#
        if result.get("characters"):
            enhanced_characters = []
            for tag in result["characters"]:
                # å°†ç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼Œå¹¶æ·»åŠ ç¬¦å·å‰ç¼€
                enhanced_tag = f"{self.SYMBOL_PREFIX_CHARACTER}{tag.replace(' ', '_')}"
                enhanced_characters.append(enhanced_tag)
            result["characters"] = enhanced_characters
        
        # åº”ç”¨ç”»å¸ˆç¬¦å·å¼ºåŒ–ï¼šå‰ç¼€@
        if result.get("artists"):
            enhanced_artists = []
            for tag in result["artists"]:
                # æ¸…ç†ç”»å¸ˆæ ‡ç­¾æ ¼å¼
                clean_tag = tag
                if clean_tag.startswith("by "):
                    clean_tag = clean_tag[3:]
                elif "artist:" in clean_tag:
                    clean_tag = clean_tag.replace("artist:", "")
                
                # å°†ç©ºæ ¼æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼Œå¹¶æ·»åŠ ç¬¦å·å‰ç¼€
                enhanced_tag = f"{self.SYMBOL_PREFIX_ARTIST}{clean_tag.replace(' ', '_')}"
                enhanced_artists.append(enhanced_tag)
            result["artists"] = enhanced_artists
        
        return result

    def format_final_output(self, classified_tags: Dict[str, List[str]], enhanced_description: str, 
                           custom_characters: list = None, custom_artists: list = None, custom_copyrights: list = None) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆè¾“å‡ºï¼Œä½¿ç”¨å›ºå®šçš„è‡ªç„¶è¯­è¨€æ ¼å¼"""
        # å›ºå®šå‰ç¼€
        prefix = "You are an assistant designed to generate anime images based on textual prompts. <Prompt Start> "
        
        # æ”¶é›†æ‰€æœ‰å…ƒç´ 
        # 1. æ€§åˆ«å’Œé‡è¯
        gender_count = ""
        if classified_tags.get("special"):
            special_tags = classified_tags["special"]
            if special_tags:
                gender_count = special_tags[0]  # å–ç¬¬ä¸€ä¸ªä½œä¸ºä¸»è¦æè¿°
        
        # 2. åˆå¹¶æ‰€æœ‰è§’è‰²
        all_characters = []
        if classified_tags.get("characters"):
            all_characters.extend(classified_tags["characters"])
        if custom_characters:
            all_characters.extend(custom_characters)
        
        # åˆ†ç¦»å¼ºåŒ–è§’è‰²å’Œæ™®é€šè§’è‰²
        enhanced_characters = []  # å¼ºåŒ–æ ¼å¼çš„è§’è‰²ï¼ˆä¿ç•™ä¸‹åˆ’çº¿ï¼‰
        normal_characters = []    # æ™®é€šè§’è‰²ï¼ˆéœ€è¦æ ¼å¼åŒ–ï¼‰
        
        for char in all_characters:
            if char.startswith("#"):
                # å¼ºåŒ–è§’è‰²ä¿æŒåŸå§‹æ ¼å¼
                enhanced_characters.append(char)
            else:
                normal_characters.append(char)
        
        # 3. åˆå¹¶æ‰€æœ‰ç‰ˆæƒ
        all_copyrights = []
        if classified_tags.get("copyrights"):
            all_copyrights.extend(classified_tags["copyrights"])
        if custom_copyrights:
            all_copyrights.extend(custom_copyrights)
        
        # 4. åˆå¹¶æ‰€æœ‰ç”»å¸ˆ
        all_artists = []
        if classified_tags.get("artists"):
            all_artists.extend(classified_tags["artists"])
        if custom_artists:
            all_artists.extend(custom_artists)
        
        # åˆ†ç¦»å¼ºåŒ–ç”»å¸ˆå’Œæ™®é€šç”»å¸ˆ
        enhanced_artists = []   # å¼ºåŒ–æ ¼å¼çš„ç”»å¸ˆï¼ˆä¿ç•™ä¸‹åˆ’çº¿ï¼‰
        normal_artists = []     # æ™®é€šç”»å¸ˆï¼ˆéœ€è¦æ ¼å¼åŒ–ï¼‰
        
        for artist in all_artists:
            if artist.startswith("@"):
                # å¼ºåŒ–ç”»å¸ˆä¿æŒåŸå§‹æ ¼å¼
                enhanced_artists.append(artist)
            else:
                # æ¸…ç†æ™®é€šç”»å¸ˆåç§°
                clean_name = artist
                if clean_name.startswith("by "):
                    clean_name = clean_name[3:]
                elif "artist:" in clean_name:
                    clean_name = clean_name.replace("artist:", "")
                normal_artists.append(clean_name)
        
        # 5. æ„å»ºå›ºå®šæ ¼å¼çš„è‡ªç„¶è¯­è¨€æè¿°
        description_parts = []
        
        # å¯¹æ™®é€šå†…å®¹è¿›è¡Œæ–‡æœ¬æ ¼å¼åŒ–ï¼ˆè½¬æ¢ä¸‹åˆ’çº¿ç­‰ï¼‰
        formatted_normal_artists = [self.apply_text_formatting(artist) for artist in normal_artists]
        formatted_normal_characters = [self.apply_text_formatting(char) for char in normal_characters]
        formatted_copyrights = [self.apply_text_formatting(copyright) for copyright in all_copyrights]
        
        # åˆå¹¶æ‰€æœ‰ç”»å¸ˆï¼ˆå…ˆæ™®é€šåå¼ºåŒ–ï¼‰
        all_display_artists = formatted_normal_artists + enhanced_artists
        
        # åˆå¹¶æ‰€æœ‰è§’è‰²ï¼ˆå…ˆæ™®é€šåå¼ºåŒ–ï¼‰  
        all_display_characters = formatted_normal_characters + enhanced_characters
        
        # ç”»å¸ˆé£æ ¼éƒ¨åˆ†
        if all_display_artists:
            if len(all_display_artists) == 1:
                style_part = f"The illustration should be in the distinct style of {all_display_artists[0]}"
            else:
                style_part = f"The illustration should be in the distinct style of {' and '.join(all_display_artists)}"
            description_parts.append(style_part)
        
        # è§’è‰²å’Œç‰ˆæƒéƒ¨åˆ†
        if all_display_characters and formatted_copyrights:
            if len(all_display_characters) == 1:
                char_part = f"depicting {gender_count} named {all_display_characters[0]}" if gender_count else f"depicting {all_display_characters[0]}"
            else:
                char_part = f"depicting {gender_count} named {' and '.join(all_display_characters)}" if gender_count else f"depicting {' and '.join(all_display_characters)}"
            
            if len(formatted_copyrights) == 1:
                char_part += f" from {formatted_copyrights[0]}"
            else:
                char_part += f" from {' and '.join(formatted_copyrights)}"
            
            description_parts.append(char_part)
        elif all_display_characters:
            if len(all_display_characters) == 1:
                char_part = f"depicting {gender_count} named {all_display_characters[0]}" if gender_count else f"depicting {all_display_characters[0]}"
            else:
                char_part = f"depicting {gender_count} named {' and '.join(all_display_characters)}" if gender_count else f"depicting {' and '.join(all_display_characters)}"
            description_parts.append(char_part)
        elif formatted_copyrights:
            if len(formatted_copyrights) == 1:
                copy_part = f"depicting {gender_count} from {formatted_copyrights[0]}" if gender_count else f"from {formatted_copyrights[0]}"
            else:
                copy_part = f"depicting {gender_count} from {' and '.join(formatted_copyrights)}" if gender_count else f"from {' and '.join(formatted_copyrights)}"
            description_parts.append(copy_part)
        elif gender_count:
            description_parts.append(f"depicting {gender_count}")
        
        # è‡ªç„¶è¯­è¨€è¯¦ç»†æè¿°
        detail_description = ""
        if enhanced_description:
            detail_description = enhanced_description
        elif classified_tags.get("general"):
            # å°†é€šç”¨æ ‡ç­¾è½¬æ¢ä¸ºç®€æ´çš„æè¿°
            general_tags = classified_tags["general"]
            if general_tags:
                # ç®€åŒ–å¤„ç†ï¼Œåªæå–å…³é”®ç‰¹å¾
                key_features = []
                for tag in general_tags[:5]:  # åªå–å‰5ä¸ªé‡è¦ç‰¹å¾
                    clean_tag = tag.replace("_", " ")
                    key_features.append(clean_tag)
                
                if key_features:
                    detail_description = f"with {', '.join(key_features)}"
        
        if detail_description:
            description_parts.append(detail_description)
        
        # æ·»åŠ è´¨é‡æ ‡ç­¾
        if classified_tags.get("quality"):
            quality_tags = classified_tags["quality"]
            positive_quality = [tag for tag in quality_tags if tag not in ["worst quality", "low quality", "bad quality", "jpeg artifacts", "blurry"]]
            if positive_quality:
                description_parts.extend(positive_quality)
        
        # ç»„åˆæœ€ç»ˆæè¿°
        if description_parts:
            final_content = ". ".join(description_parts)
            # ç¡®ä¿å¥å­ä»¥å¥å·ç»“å°¾
            if not final_content.endswith('.') and not any(final_content.endswith(q) for q in ["masterpiece", "best quality", "high quality"]):
                final_content += "."
        else:
            final_content = "An anime-style illustration."
        
        return prefix + final_content

    def process_prompt(self, danbooru_tags: str, drawing_theme: str,
                      api_url: str, api_key: str, model_name: str,
                      classification_mode: str = "local_knowledge", 
                      custom_characters: str = "", custom_artists: str = "", custom_copyrights: str = "", 
                      enable_symbol_enhancement: bool = True,
                      proxy_http: str = "", proxy_https: str = "") -> Tuple[str, str, str, Dict, str]:
        """ä¸»å¤„ç†å‡½æ•°"""
        
        log_entries = []
        log_entries.append("=== é«˜çº§æç¤ºè¯å¤„ç†å¼€å§‹ ===")
        log_entries.append(f"è¾“å…¥æ ‡ç­¾: {danbooru_tags[:self.MAX_LOG_LENGTH]}{'...' if len(danbooru_tags) > self.MAX_LOG_LENGTH else ''}")
        log_entries.append(f"ç»˜å›¾ä¸»é¢˜: {drawing_theme[:self.MAX_LOG_LENGTH]}{'...' if len(drawing_theme) > self.MAX_LOG_LENGTH else ''}")
        
        # è®°å½•ä»£ç†è®¾ç½®
        if proxy_http or proxy_https:
            log_entries.append(f"ğŸŒ æ‰‹åŠ¨ä»£ç†è®¾ç½® - HTTP: {proxy_http or 'æ— '}, HTTPS: {proxy_https or 'æ— '}")
        else:
            log_entries.append("ğŸŒ å°†è‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿä»£ç†è®¾ç½®")
        
        # æ­¥éª¤1: æ•°å­—æ›¿æ¢
        processed_tags = self.replace_numbers_with_english(danbooru_tags)
        if processed_tags != danbooru_tags:
            log_entries.append("æ•°å­—æ›¿æ¢å®Œæˆ")
        
        # æ­¥éª¤2: è§£æè‡ªå®šä¹‰æ ‡ç­¾ï¼ˆç›´æ¥æ·»åŠ åˆ°è¾“å‡ºçš„æ ‡ç­¾ï¼‰
        custom_chars_list = self.parse_custom_tags(custom_characters)
        custom_artists_list = self.parse_custom_tags(custom_artists)
        custom_copyrights_list = self.parse_custom_tags(custom_copyrights)
        log_entries.append(f"è‡ªå®šä¹‰æ ‡ç­¾è§£æå®Œæˆ - è§’è‰²:{len(custom_chars_list)}, ç”»å¸ˆ:{len(custom_artists_list)}, ç‰ˆæƒ:{len(custom_copyrights_list)}")
        
        # ä¿ç•™ç©ºé›†åˆç”¨äºåˆ†ç±»æ—¶çš„æŸ¥æ‰¾
        custom_chars_set = set(custom_chars_list) if custom_chars_list else set()
        custom_artists_set = set(custom_artists_list) if custom_artists_list else set()
        custom_copyrights_set = set(custom_copyrights_list) if custom_copyrights_list else set()
        
        # æ­¥éª¤3: åˆ†ç±»æ ‡ç­¾ï¼ˆé€‰æ‹©åˆ†ç±»æ¨¡å¼ï¼‰
        classified_tags = {}
        if processed_tags.strip():
            if classification_mode == "llm_classification" and api_key:
                classified_tags = self.classify_tags_with_llm(processed_tags, api_url, api_key, model_name, proxy_http, proxy_https)
                log_entries.append(f"LLMæ ‡ç­¾åˆ†ç±»å®Œæˆ - æ€»è®¡:{sum(len(tags) for tags in classified_tags.values())}ä¸ªæ ‡ç­¾")
            else:
                # ä½¿ç”¨é…ç½®çš„çŸ¥è¯†åº“è·¯å¾„
                knowledge_base = self.load_knowledge_base_from_folder(self.KNOWLEDGE_BASE_PATH)
                if knowledge_base:
                    total_tags = sum(len(tags) for tags in knowledge_base.values() if tags)
                    log_entries.append(f"åŠ è½½Tag knowledgeæˆåŠŸ - {len(knowledge_base)} ä¸ªç±»åˆ«ï¼Œ{total_tags} ä¸ªæ ‡ç­¾")
                else:
                    log_entries.append("Tag knowledgeä¸ºç©ºï¼Œä½¿ç”¨å†…ç½®çŸ¥è¯†åº“è¿›è¡Œåˆ†ç±»")
                
                classified_tags = self.classify_tags_with_knowledge_base(
                    processed_tags, knowledge_base, custom_chars_set, custom_artists_set, custom_copyrights_set
                )
                log_entries.append(f"æœ¬åœ°çŸ¥è¯†åº“åˆ†ç±»å®Œæˆ - æ€»è®¡:{sum(len(tags) for tags in classified_tags.values())}ä¸ªæ ‡ç­¾")
        else:
            # åˆå§‹åŒ–ç©ºåˆ†ç±»
            classified_tags = {category: [] for category in ["special", "characters", "copyrights", "artists", "general", "quality", "meta", "rating"]}
            log_entries.append("æ— æ ‡ç­¾è¾“å…¥ï¼Œè·³è¿‡åˆ†ç±»")
        
        # æ­¥éª¤4: LLMå¢å¼º
        enhanced_description = ""
        if api_key:
            log_entries.append(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
            enhanced_description = self.enhance_with_llm(processed_tags, drawing_theme, api_url, api_key, model_name, proxy_http, proxy_https)
            if enhanced_description and not enhanced_description.startswith("APIè°ƒç”¨å¤±è´¥"):
                log_entries.append("LLMå¢å¼ºå®Œæˆ")
            else:
                log_entries.append(f"LLMå¢å¼ºå¤±è´¥: {enhanced_description}")
                enhanced_description = ""  # æ¸…ç©ºå¤±è´¥çš„ç»“æœ
        else:
            log_entries.append("LLMå¢å¼ºè·³è¿‡ - æ— APIå¯†é’¥")
        
        # æ­¥éª¤5: åº”ç”¨ç¬¦å·å¼ºåŒ–ï¼ˆåŒ…æ‹¬è‡ªå®šä¹‰æ ‡ç­¾ï¼‰
        enhanced_tags = self.apply_symbol_enhancement(classified_tags, enable_symbol_enhancement)
        
        # å¯¹è‡ªå®šä¹‰æ ‡ç­¾ä¹Ÿåº”ç”¨ç¬¦å·å¼ºåŒ–
        if enable_symbol_enhancement:
            if custom_chars_list:
                custom_chars_list = [f"{self.SYMBOL_PREFIX_CHARACTER}{char.replace(' ', '_')}" for char in custom_chars_list]
            if custom_artists_list:
                custom_artists_list = [f"{self.SYMBOL_PREFIX_ARTIST}{artist.replace(' ', '_')}" for artist in custom_artists_list]
            log_entries.append("ç¬¦å·å¼ºåŒ–å®Œæˆ - @ç”»å¸ˆå¼ºåŒ–, #è§’è‰²å¼ºåŒ–ï¼ˆåŒ…æ‹¬è‡ªå®šä¹‰æ ‡ç­¾ï¼‰")
        else:
            log_entries.append("è·³è¿‡ç¬¦å·å¼ºåŒ–")
        
        # æ­¥éª¤6: æ–‡æœ¬æ ¼å¼åŒ–
        formatted_enhanced = self.apply_text_formatting(enhanced_description)
        
        log_entries.append("æ–‡æœ¬æ ¼å¼åŒ–å°†åœ¨æœ€ç»ˆè¾“å‡ºæ—¶å¤„ç†")
        
        # æ­¥éª¤7: ç”Ÿæˆæœ€ç»ˆè¾“å‡ºï¼Œåˆå¹¶è‡ªå®šä¹‰æ ‡ç­¾
        final_prompt = self.format_final_output(enhanced_tags, formatted_enhanced, 
                                               custom_chars_list, custom_artists_list, custom_copyrights_list)
        
        # ç”Ÿæˆæ ¼å¼åŒ–æç¤ºè¯ï¼ˆå»é™¤å‰ç¼€çš„çº¯å†…å®¹ç‰ˆæœ¬ï¼‰
        formatted_prompt = final_prompt.replace("You are an assistant designed to generate anime images based on textual prompts. <Prompt Start> ", "")
        
        log_entries.append("æœ€ç»ˆè¾“å‡ºç”Ÿæˆå®Œæˆ")
        log_entries.append("=== å¤„ç†å®Œæˆ ===")
        
        processing_log = "\n".join(log_entries)
        
        return (final_prompt, formatted_enhanced, formatted_prompt, enhanced_tags, processing_log)


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "AdvancedPromptProcessor": AdvancedPromptProcessor,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AdvancedPromptProcessor": "é«˜çº§æç¤ºè¯å¤„ç†å™¨",
}